{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie per lettura file\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import psutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "#Kfold and GridSearch\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "\n",
    "# Grafici\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "# Data Analysis\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    precision_recall_curve, classification_report, confusion_matrix,\n",
    "    roc_curve, roc_auc_score, average_precision_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Modelli con Alberi\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Librerie Torch per MLP\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, SubsetRandomSampler\n",
    "from torchmetrics import F1Score, Accuracy, Precision, Recall\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "# Explainable AI (SHAP)\n",
    "import shap\n",
    "\n",
    "# Librerie per gestione dati parallela\n",
    "import modin.pandas as mpd\n",
    "import modin.config as cfg\n",
    "\n",
    "# Visualizzazione matrice di confusione\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import optuna\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg') \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"FigureCanvasAgg is non-interactive, and thus cannot be shown\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to have in the same directory the files obtained by ranking_best_drugs.ipynb so the cleaned transcriptomic and the ranked drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the files\n",
    "score_df = pd.read_csv(\"Preprocessing/drug_scores_with_targets.csv\")\n",
    "df_clean = pd.read_csv(\"Preprocessing/transcrittoma_pulito.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Score</th>\n",
       "      <th>Drug_name</th>\n",
       "      <th>Targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>268.0</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>YM155</td>\n",
       "      <td>['BIRC5']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>166.0</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>FTI-277</td>\n",
       "      <td>['FDPS']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>194.0</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>AUY922</td>\n",
       "      <td>['HSP90AA1']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1175.0</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>AG-014699</td>\n",
       "      <td>['PARP2', 'PARP1']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>135.0</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>Gemcitabine</td>\n",
       "      <td>['DNA_damage']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>MS-275</td>\n",
       "      <td>['O15379,P56524,Q13547,Q8WUI4,Q92769,Q96DB2,Q9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>157.0</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>JNK-9L</td>\n",
       "      <td>['JNK']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>197.0</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>Bryostatin 1</td>\n",
       "      <td>['PRKCA']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1527.0</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>GDC0941 (rescreen)</td>\n",
       "      <td>['PI3K']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>87.0</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>GW843682X</td>\n",
       "      <td>['PLK1']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>184.0</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>BMS-754807</td>\n",
       "      <td>['IGF1R']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1023.0</td>\n",
       "      <td>-0.000983</td>\n",
       "      <td>GW 441756</td>\n",
       "      <td>['NTRK1']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>63.0</td>\n",
       "      <td>-0.001264</td>\n",
       "      <td>BMS-509744</td>\n",
       "      <td>['ITK']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>71.0</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>Pyrimethamine</td>\n",
       "      <td>['DHFR']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>185.0</td>\n",
       "      <td>-0.001548</td>\n",
       "      <td>OSI-906</td>\n",
       "      <td>['IGF1R']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Drug     Score           Drug_name  \\\n",
       "185   268.0  0.000936               YM155   \n",
       "186   166.0  0.000682             FTI-277   \n",
       "187   194.0  0.000590              AUY922   \n",
       "188  1175.0  0.000514           AG-014699   \n",
       "189   135.0  0.000416         Gemcitabine   \n",
       "190    88.0  0.000220              MS-275   \n",
       "191   157.0  0.000211              JNK-9L   \n",
       "192   197.0  0.000141        Bryostatin 1   \n",
       "193  1527.0  0.000081  GDC0941 (rescreen)   \n",
       "194    87.0 -0.000111           GW843682X   \n",
       "195   184.0 -0.000513          BMS-754807   \n",
       "196  1023.0 -0.000983           GW 441756   \n",
       "197    63.0 -0.001264          BMS-509744   \n",
       "198    71.0 -0.001509       Pyrimethamine   \n",
       "199   185.0 -0.001548             OSI-906   \n",
       "\n",
       "                                               Targets  \n",
       "185                                          ['BIRC5']  \n",
       "186                                           ['FDPS']  \n",
       "187                                       ['HSP90AA1']  \n",
       "188                                 ['PARP2', 'PARP1']  \n",
       "189                                     ['DNA_damage']  \n",
       "190  ['O15379,P56524,Q13547,Q8WUI4,Q92769,Q96DB2,Q9...  \n",
       "191                                            ['JNK']  \n",
       "192                                          ['PRKCA']  \n",
       "193                                           ['PI3K']  \n",
       "194                                           ['PLK1']  \n",
       "195                                          ['IGF1R']  \n",
       "196                                          ['NTRK1']  \n",
       "197                                            ['ITK']  \n",
       "198                                           ['DHFR']  \n",
       "199                                          ['IGF1R']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.iloc[185:200,:] #show the best 30 drugs (the first one has score None due to the lack of data, so it is not taken in consideration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you can run models that predict drug sensitivity only. The analysis specifically focuses on the top 30 drugs, although you can include more if desired. However, note that drugs with a negative score perform worse than a random model and are therefore not recommended for use—this applies especially to drugs ranked beyond the 194th position.\n",
    "\n",
    "Currently, only the functions used in the article are implemented here. However, models using scikit-learn can be easily added by modifying this structure, which is based on the XGBoost (XGB) model.\n",
    "\n",
    "##### Choose the ensemble models \n",
    "\n",
    "models = [XGBClassifier for _ in range(5)]\n",
    "\n",
    "##### Seed\n",
    "rf_params = {\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "##### Param grid space for Hyperparameter Tuning\n",
    "params = {\n",
    "    \"n_estimators\": randint(10, 301),              \n",
    "    \"max_depth\": randint(3, 11),                     \n",
    "    \"learning_rate\": [1,0.1,0.01,0.3],             \n",
    "    \"subsample\": [0.4,0.5,0.6,0.8,1],                \n",
    "    \"colsample_bytree\": [0.7,0.9,1],   \n",
    "    \"min_child_weight\": randint(1, 11),          \n",
    "    \"gamma\": [0,0.1,0.01,0.3,0.5]                         \n",
    "}\n",
    "\n",
    "##### Directory to save the results\n",
    "dir = 'Results/Models_Sensitivity_prova/XGB'\n",
    "\n",
    "#### Run the function\n",
    "train_model(df_clean, rf_params,models, params, shap_dir = dir, l=31) #if you want more drugs to be evaluated increase l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optuna objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model, X_train, y_train, X_val, y_val, base_params, param_grid):\n",
    "    '''\n",
    "    Objective function for hyperparameter optimization using Optuna.\n",
    "\n",
    "    Parameters:\n",
    "    - trial: Optuna Trial object, used to suggest new hyperparameter values.\n",
    "    - model: scikit-learn-compatible model to be optimized.\n",
    "    - X_train, y_train: training data.\n",
    "    - X_val, y_val: validation data for performance evaluation.\n",
    "    - base_params: dictionary of fixed model parameters (you can see it when you call the main function)\n",
    "    - param_grid: dictionary defining the search space for each hyperparameter ((you can see it when you call the main function))\n",
    "\n",
    "    Returns:\n",
    "    - average_precision_score on the validation set, which will be maximized.\n",
    "    '''\n",
    "\n",
    "    params = base_params.copy()\n",
    "\n",
    "    for key, space in param_grid.items():\n",
    "        if isinstance(space, list):\n",
    "            params[key] = trial.suggest_categorical(key, space)\n",
    "        elif isinstance(space, range):\n",
    "            params[key] = trial.suggest_int(key, min(space), max(space))\n",
    "        elif hasattr(space, \"rvs\"):\n",
    "            a, b = space.a, space.b\n",
    "            params[key] = trial.suggest_int(key, a, b - 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported type for parameter {key}: {type(space)}\")\n",
    "\n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    return average_precision_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modello_base(train_set, train_cells, rf_params={}, \n",
    "               base_models=None, param_grid=None, n_splits=5, n_trials = 10, random_state=42):\n",
    "    \n",
    "    '''\n",
    "    Function to train and evaluate ensemble ML models using K-Fold cross-validation as explained in the article,\n",
    "    SMOTE for class balancing, and Optuna for hyperparameter optimization.\n",
    "\n",
    "    Parameters:\n",
    "    - train_set: DataFrame containing the full training data, including features and labels.\n",
    "    - train_cells: Array-like list of cell line identifiers used for splitting the data into folds.\n",
    "    - rf_params: Dictionary of fixed parameters for the base model(s) (optional).\n",
    "    - base_models: List of model constructors (e.g., [RandomForestClassifier, ...]); one per fold. If None, RandomForestClassifier is used for all folds.\n",
    "    - param_grid: Dictionary defining the search space for hyperparameters to tune with Optuna.\n",
    "    - n_splits: Number of folds for cross-validation (default is 5).\n",
    "    - n_trials: Number of Optuna trials per fold for hyperparameter tuning (default is 10).\n",
    "    - random_state: Seed for reproducibility (used in SMOTE, CV splitting, and Optuna sampler).\n",
    "\n",
    "    Returns:\n",
    "    - models_per_fold: A list of dictionaries, each containing the trained model, evaluation scores (AUC, average precision, F1), and best hyperparameters for a fold.\n",
    "    - y_val_all: Combined list of true validation labels across all folds.\n",
    "    - y_val_pred_all: Combined list of predicted probabilities across all folds.\n",
    "    '''\n",
    "\n",
    "    #Base models if the models given to the function are None\n",
    "    if base_models is None:\n",
    "        base_models = [RandomForestClassifier for _ in range(n_splits)]\n",
    "    \n",
    "    #Parameter grid if the ones given to the function are None\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [500],\n",
    "            \"max_depth\": [7]\n",
    "        }\n",
    "    \n",
    "    # Ensemble Models\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    models_per_fold = []\n",
    "    y_val_all, y_val_pred_all = [], []\n",
    "    i = 0\n",
    "\n",
    "    for train_idx, val_idx in kf.split(train_cells):\n",
    "\n",
    "        #Trainin and Validation for each split\n",
    "        train_cells_fold = train_cells[train_idx]\n",
    "        val_cells_fold = train_cells[val_idx]\n",
    "\n",
    "        train_fold = train_set[train_set[\"Cell_line_cosmic_identifiers\"].isin(train_cells_fold)]\n",
    "        val_fold = train_set[train_set[\"Cell_line_cosmic_identifiers\"].isin(val_cells_fold)]\n",
    "\n",
    "        X_train = train_fold.drop(columns=[\"IC50\", \"Sensitivity\", \"Cell_line_cosmic_identifiers\", \"Screened_Compounds_\", \"Sample_Names\", \"Drug_id\"])\n",
    "        y_train = train_fold[\"Sensitivity\"]\n",
    "\n",
    "        X_val = val_fold.drop(columns=[\"IC50\", \"Sensitivity\", \"Cell_line_cosmic_identifiers\", \"Screened_Compounds_\", \"Sample_Names\", \"Drug_id\"])\n",
    "        y_val = val_fold[\"Sensitivity\"]\n",
    "\n",
    "        #Smote for balancing classes\n",
    "        smote = SMOTE(random_state=42) \n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "        mod = base_models[i](**rf_params)\n",
    "\n",
    "        sampler = optuna.samplers.TPESampler(seed=42)\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "\n",
    "        study.optimize(\n",
    "            lambda trial: objective(trial, mod, X_train_resampled, y_train_resampled, X_val, y_val, rf_params, param_grid),\n",
    "            n_trials=n_trials\n",
    "        )\n",
    "\n",
    "        #Predict probability\n",
    "        best_params = study.best_params\n",
    "        best_params[\"random_state\"] = 42\n",
    "        rf_model = mod.set_params(**best_params)\n",
    "        rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "        y_pred_prob = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "\n",
    "        y_val_all.extend(y_val)\n",
    "        y_val_pred_all.extend(y_pred_prob)\n",
    "        auc_score = roc_auc_score(y_val, y_pred_prob)\n",
    "        auc_pr = average_precision_score(y_val, y_pred_prob)\n",
    "        f1 = f1_score(y_val, (y_pred_prob > 0.4).astype(int))\n",
    "\n",
    "        #Saving the metrics for the validation because auc_pr is used to predict the final probability as explained in the article\n",
    "        models_per_fold.append({\n",
    "            \"model\": rf_model,\n",
    "            \"auc_score\": auc_score,\n",
    "            \"auc_pr\": auc_pr,\n",
    "            \"f1_score\": f1,\n",
    "            \"best_params\": best_params\n",
    "        })\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return models_per_fold, y_val_all, y_val_pred_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(train_set, train_cells, shap_dir, drug_name, n_splits=5, n_trials = 10, random_state=42):\n",
    "    \n",
    "    '''\n",
    "    Function to test and evaluate already trained ensemble ML models using K-Fold cross-validation as explained in the article,\n",
    "    SMOTE for class balancing, and Optuna for hyperparameter optimization.\n",
    "\n",
    "    Parameters:\n",
    "    - train_set: DataFrame containing the full training data, including features and labels.\n",
    "    - train_cells: Array-like list of cell line identifiers used for splitting the data into folds.\n",
    "    - shap_dir: directory where are saved the models\n",
    "    – drug_name: name of the drug\n",
    "    - n_splits: Number of folds for cross-validation (default is 5).\n",
    "    - n_trials: Number of Optuna trials per fold for hyperparameter tuning (default is 10).\n",
    "    - random_state: Seed for reproducibility (used in SMOTE, CV splitting, and Optuna sampler).\n",
    "\n",
    "    Returns:\n",
    "    - models_per_fold: A list of dictionaries, each containing the trained model, evaluation scores (AUC, average precision, F1), and best hyperparameters for a fold.\n",
    "    - y_val_all: Combined list of true validation labels across all folds.\n",
    "    - y_val_pred_all: Combined list of predicted probabilities across all folds.\n",
    "    '''\n",
    "\n",
    "    # Ensemble Models\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    models_per_fold = []\n",
    "    y_val_all, y_val_pred_all = [], []\n",
    "    i = 0\n",
    "\n",
    "    for train_idx, val_idx in kf.split(train_cells):\n",
    "\n",
    "        #Trainin and Validation for each split\n",
    "        train_cells_fold = train_cells[train_idx]\n",
    "        val_cells_fold = train_cells[val_idx]\n",
    "\n",
    "        train_fold = train_set[train_set[\"Cell_line_cosmic_identifiers\"].isin(train_cells_fold)]\n",
    "        val_fold = train_set[train_set[\"Cell_line_cosmic_identifiers\"].isin(val_cells_fold)]\n",
    "\n",
    "        X_train = train_fold.drop(columns=[\"IC50\", \"Sensitivity\", \"Cell_line_cosmic_identifiers\", \"Screened_Compounds_\", \"Sample_Names\", \"Drug_id\"])\n",
    "        y_train = train_fold[\"Sensitivity\"]\n",
    "\n",
    "        X_val = val_fold.drop(columns=[\"IC50\", \"Sensitivity\", \"Cell_line_cosmic_identifiers\", \"Screened_Compounds_\", \"Sample_Names\", \"Drug_id\"])\n",
    "        y_val = val_fold[\"Sensitivity\"]\n",
    "\n",
    "        #Smote for balancing classes\n",
    "        smote = SMOTE(random_state=42) \n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Testing model already trained\n",
    "        models_dir = os.path.join(shap_dir, f\"{drug_name}_models\")\n",
    "        model_path = os.path.join(models_dir, f\"model_fold_{i}.pkl\")\n",
    "        loaded_obj = joblib.load(model_path)\n",
    "        model = loaded_obj['model']\n",
    "\n",
    "\n",
    "        y_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "\n",
    "        y_val_all.extend(y_val)\n",
    "        y_val_pred_all.extend(y_pred_prob)\n",
    "        auc_score = roc_auc_score(y_val, y_pred_prob)\n",
    "        auc_pr = average_precision_score(y_val, y_pred_prob)\n",
    "        f1 = f1_score(y_val, (y_pred_prob > 0.4).astype(int))\n",
    "\n",
    "        #Saving the metrics for the validation because auc_pr is used to predict the final probability as explained in the article\n",
    "        models_per_fold.append({\n",
    "            \"model\":model,\n",
    "            \"auc_score\": auc_score,\n",
    "            \"auc_pr\": auc_pr,\n",
    "            \"f1_score\": f1\n",
    "        })\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return models_per_fold, y_val_all, y_val_pred_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(\n",
    "    y_test,\n",
    "    y_pred_test,\n",
    "    y_val_all,\n",
    "    y_val_pred_all,\n",
    "    shap_dir,\n",
    "    drug_name,\n",
    "    specific_drug,\n",
    "    y_pred_test_prob,\n",
    "    all_fpr_test,\n",
    "    all_precision_test,\n",
    "    drug_names,\n",
    "    recall_val,\n",
    "    precision_val,\n",
    "    avg_auc_score,\n",
    "    auc_score_test,\n",
    "    avg_auc_pr,\n",
    "    auc_pr_test,\n",
    "    best_threshold,\n",
    "    cumulative_cm\n",
    "):\n",
    "        '''\n",
    "        Function to generate plots\n",
    "        '''\n",
    "        cm = confusion_matrix(y_test, y_pred_test)\n",
    "        cumulative_cm += cm\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "\n",
    "\n",
    "        cm_fig_path = os.path.join(shap_dir, f\"{drug_name}_confusion_matrix.png\")\n",
    "        disp.plot(cmap=\"Blues\")\n",
    "        plt.title(f\"Confusion Matrix - {drug_name}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(cm_fig_path)\n",
    "        plt.close()\n",
    "\n",
    "        fpr_val, tpr_val, _ = roc_curve(y_val_all, y_val_pred_all)\n",
    "        fpr_test, tpr_test, _ = roc_curve(y_test, y_pred_test_prob)\n",
    "        precision_test, recall_test, _ = precision_recall_curve(y_test, y_pred_test_prob)\n",
    "\n",
    "        all_fpr_test.append((fpr_test, tpr_test))\n",
    "        all_precision_test.append((recall_test, precision_test))\n",
    "        drug_names.append(specific_drug)\n",
    "\n",
    "        roc_fig_path = os.path.join(shap_dir, f\"{drug_name}_roc_curve.png\")\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(fpr_val, tpr_val, label=f'Validation AUC = {avg_auc_score:.3f}')\n",
    "        plt.plot(fpr_test, tpr_test, label=f'Test AUC = {auc_score_test:.3f}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve - {drug_name}\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(recall_val, precision_val, label=f'Validation AUC-PR = {avg_auc_pr:.3f}')\n",
    "        plt.plot(recall_test, precision_test, label=f'Test AUC-PR = {auc_pr_test:.3f}')\n",
    "        plt.axvline(x=best_threshold, color='r', linestyle=\"--\", label=f\"Best Threshold = {best_threshold:.3f}\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.title(f\"Precision-Recall Curve - {drug_name}\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(roc_fig_path)\n",
    "        plt.close()\n",
    "\n",
    "        cutoff_range = np.arange(y_pred_test_prob.min(), y_pred_test_prob.max(), 0.01)\n",
    "        precisions_cutoff = []\n",
    "        recalls_cutoff = []\n",
    "\n",
    "        for cutoff in cutoff_range:\n",
    "            predicted_sensitivity = (y_pred_test_prob > cutoff).astype(int)\n",
    "            precision = precision_score(y_test, predicted_sensitivity, zero_division=0)\n",
    "            recall = recall_score(y_test, predicted_sensitivity, zero_division=0)\n",
    "\n",
    "            precisions_cutoff.append(precision)\n",
    "            recalls_cutoff.append(recall)\n",
    "\n",
    "        plt.figure(figsize=(7, 4))\n",
    "        plt.plot(cutoff_range, precisions_cutoff, marker='o', label='Precision', color='blue')\n",
    "        plt.plot(cutoff_range, recalls_cutoff, marker='x', label='Recall', color='orange')\n",
    "        plt.title(f\"Precision & Recall vs Probabilities Cut-off - {drug_name}\")\n",
    "        plt.xlabel(\"Probabilities Cut-off (on predicted values) \")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.ylim(0, 1.05)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{shap_dir}/{drug_name}_precision_recall_curve_rf.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shap_plots(\n",
    "    models_per_fold,\n",
    "    X_test,\n",
    "    test_set,\n",
    "    df_clean,\n",
    "    shap_dir,\n",
    "    drug_name,\n",
    "    specific_drug\n",
    "):\n",
    "        '''\n",
    "        Function to compute SHAP and to generate plots\n",
    "        '''\n",
    "\n",
    "        # Directory SHAP\n",
    "        shap_dir_drug = os.path.join(shap_dir, f\"{drug_name}\")\n",
    "        os.makedirs(shap_dir_drug, exist_ok=True)  \n",
    "\n",
    "        shap_values_list = []\n",
    "        print(f\"\\nCalcolo SHAP per {drug_name} su {len(models_per_fold)} modelli...\")\n",
    "\n",
    "\n",
    "        ## Shap values for each model-cell_line\n",
    "        for i, model_info in enumerate(models_per_fold):\n",
    "            model = model_info[\"model\"]\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            X_test_aligned = X_test[model.feature_names_in_]  \n",
    "            shap_values = explainer.shap_values(X_test_aligned, check_additivity=False)\n",
    "            if isinstance(shap_values, list):\n",
    "                sv = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
    "            else:\n",
    "                sv = shap_values\n",
    "\n",
    "            if sv.shape[1] != X_test.shape[1]:\n",
    "                print(f\"⚠️ SHAP shape mismatch: got {sv.shape}, expected ({X_test.shape[0]}, {X_test.shape[1]})\")\n",
    "                continue\n",
    "\n",
    "            shap_values_list.append(sv)\n",
    "\n",
    "        ## MEAN SHAP for each model\n",
    "        if shap_values_list:\n",
    "            shap_df_list = []\n",
    "            for sv in shap_values_list:\n",
    "                if sv.ndim == 3:\n",
    "                    sv = sv[:, :, 1]\n",
    "                shap_df_list.append(pd.DataFrame(sv, columns=X_test.columns, index=X_test.index))\n",
    "\n",
    "            mean_shap_df = sum(shap_df_list) / len(shap_df_list)\n",
    "\n",
    "            for idx, row in X_test.iterrows():\n",
    "       \n",
    "                cell_line_id = test_set.loc[idx][\"Cell_line_cosmic_identifiers\"]\n",
    "                matching_rows = df_clean[df_clean[\"Cell_line_cosmic_identifiers\"] == cell_line_id]\n",
    "\n",
    "                if not matching_rows.empty:\n",
    "                    cell_name = matching_rows[\"cell_name\"].iloc[0] \n",
    "                else:\n",
    "                    print(f\" Nessuna riga trovata per cell_line_id {cell_line_id}\")\n",
    "                    continue  \n",
    "\n",
    "                shap_values_row = mean_shap_df.loc[idx]\n",
    "                sorted_idx = np.argsort(np.abs(shap_values_row.values))[::-1]\n",
    "                sorted_features = X_test.columns[sorted_idx]\n",
    "                sorted_shap = shap_values_row.values[sorted_idx]\n",
    "                sorted_vals = row.values[sorted_idx]\n",
    "\n",
    "                if isinstance(explainer.expected_value, (list, np.ndarray)):\n",
    "                        base_value = explainer.expected_value[1] if len(explainer.expected_value) > 1 else explainer.expected_value[0]\n",
    "                else:\n",
    "                        base_value = explainer.expected_value\n",
    "\n",
    "                ## 1) Waterfall Plot\n",
    "                shap.waterfall_plot(shap.Explanation(\n",
    "                        values=sorted_shap,\n",
    "                        base_values=base_value,  \n",
    "                        data=sorted_vals,\n",
    "                        feature_names=sorted_features\n",
    "                    ))\n",
    "\n",
    "                plt.suptitle(f\"SHAP Waterfall - Cell Line: {cell_name}\", fontsize=14)\n",
    "                fig = plt.gcf()\n",
    "                fig_path = os.path.join(shap_dir_drug, f\"{cell_name}_shap_waterfall.png\")\n",
    "                fig.savefig(fig_path, format=\"png\") \n",
    "                plt.close(fig)  \n",
    "\n",
    "\n",
    "                ## 2) shap_bar_top 5 sensitivity and resistance\n",
    "                shap_series = shap_values_row.sort_values()\n",
    "                negativi = shap_series.head(5)\n",
    "                positivi = shap_series.tail(5)\n",
    "                combined = pd.concat([negativi, positivi])\n",
    "                colori = ['lightcoral'] * 5 + ['skyblue'] * 5\n",
    "\n",
    "                plt.figure(figsize=(5, 4))\n",
    "                plt.barh(combined.index[::-1], combined.values[::-1], color=colori[::-1])\n",
    "                plt.axvline(0, color='gray', linestyle='--')\n",
    "                plt.title(f\"Top 5 ± SHAP - {cell_name}\", fontsize=10)\n",
    "                plt.xlabel(\"SHAP Value (Effect)\")\n",
    "                plt.tight_layout()\n",
    "                fig_bar_path = os.path.join(shap_dir_drug, f\"{cell_name}_shap_bar_top5.png\")\n",
    "                plt.savefig(fig_bar_path, format=\"png\")\n",
    "                plt.close()\n",
    "\n",
    "            ### Grafici SHAP sul farmaco ###\n",
    "\n",
    "            ## shap_top5_mean_bar\n",
    "            shap_mean = mean_shap_df.mean(axis=0).sort_values()\n",
    "            top5_neg = shap_mean.head(5)\n",
    "            top5_pos = shap_mean.tail(5)\n",
    "            combined = pd.concat([top5_neg, top5_pos])\n",
    "            colori = ['lightcoral'] * 5 + ['skyblue'] * 5\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.barh(combined.index[::-1], combined.values[::-1], color=colori[::-1])\n",
    "            plt.axvline(0, color='gray', linestyle='--')\n",
    "            plt.title(f\"SHAP Top 5 ± - {drug_name} (media su tutte le cell)\", fontsize=11)\n",
    "            plt.xlabel(\"SHAP value (mean)\")\n",
    "            plt.tight_layout()\n",
    "            fig_group_bar_path = os.path.join(shap_dir_drug, f\"{drug_name}_shap_top5_mean_bar.png\")\n",
    "            plt.savefig(fig_group_bar_path, format=\"png\")\n",
    "            plt.close()\n",
    "\n",
    "            abs_shap_df_list = [df.abs() for df in shap_df_list]\n",
    "            mean_abs_shap_df = sum(abs_shap_df_list) / len(abs_shap_df_list)\n",
    "            mean_abs_importance = mean_abs_shap_df.mean(axis=0)\n",
    "            ## top 20 features\n",
    "            top20_features = (\n",
    "                mean_shap_df.abs().mean(axis=0)\n",
    "                .sort_values(ascending=False)\n",
    "                .head(20)\n",
    "            )\n",
    "            top20_features = mean_abs_importance.sort_values(ascending=False).head(20)\n",
    "            top20_features_path = os.path.join(shap_dir_drug, \"top20_features.csv\")\n",
    "            top20_features.to_csv(top20_features_path, header=[\"mean_abs_shap_value\"])\n",
    "\n",
    "\n",
    "            ## SHAP summary plot\n",
    "            top10_indices = mean_abs_importance.sort_values(ascending=False).head(10).index\n",
    "            top10_shap_values = mean_shap_df[top10_indices].values\n",
    "            top10_X_test = X_test[top10_indices]\n",
    "\n",
    "            plt.figure()\n",
    "            shap.summary_plot(top10_shap_values, top10_X_test, feature_names=top10_indices, show=False)\n",
    "            plt.title(f\"SHAP Summary Plot (Top 10) - {drug_name}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(shap_dir_drug, \"shap_summary_plot.png\"))\n",
    "            plt.close()\n",
    "            \n",
    "            ## SHAP bar plot\n",
    "            shap_bar_fig_path = os.path.join(shap_dir_drug, \"shap_bar_plot.png\")\n",
    "            plt.figure()\n",
    "            shap.summary_plot(mean_shap_df.values, X_test, feature_names=X_test.columns, plot_type=\"bar\", show=False)\n",
    "            plt.title(f\"SHAP Bar Plot (Media) - {drug_name}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(shap_bar_fig_path)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df_clean, rf_params, base_models, param_grid, shap_dir = 'RF_SENSITIVITY', l=31):\n",
    "    '''\n",
    "    Train models to predict drug sensitivity for multiple drugs,\n",
    "    evaluate their performance, generate visualizations, and compute SHAP explanations.\n",
    "\n",
    "    The function performs the following steps per drug:\n",
    "    - Encodes categorical features.\n",
    "    - Splits the dataset by cell lines into training and test sets.\n",
    "    - Uses K-Fold cross-validation and SMOTE on training data.\n",
    "    - Applies Optuna for hyperparameter optimization.\n",
    "    - Evaluates on both validation and test sets (AUC, F1, Precision, Recall).\n",
    "    - Saves trained models, performance metrics, confusion matrices, ROC/PR curves.\n",
    "    - Computes SHAP values for test set samples and saves waterfall/summary plots.\n",
    "\n",
    "    Parameters:\n",
    "    - df_clean: Preprocessed and cleaned DataFrame containing features and labels.\n",
    "    - rf_params: Dictionary of fixed parameters to use for RandomForestClassifier.\n",
    "    - base_models: List of model classes to use per fold (e.g. [RandomForestClassifier, ...]).\n",
    "    - param_grid: Dictionary of hyperparameters to tune via Optuna.\n",
    "    - shap_dir: Directory where models, plots, and SHAP outputs will be saved (default 'RF_SENSITIVITY').\n",
    "    - l: Number of drugs to process (default is 31; starts from index 1 of `score_df[\"Drug\"]`).\n",
    "\n",
    "    Returns:\n",
    "    - Saves per-drug results and visualizations in the specified `shap_dir`.\n",
    "    - Outputs a summary CSV (`rf_drug_sensitivity_results.csv`) with metrics per drug.\n",
    "    - Prints final classification report and cumulative F1 score over all predictions.\n",
    "    '''\n",
    "\n",
    "    # Directory\n",
    "    if not os.path.exists(shap_dir):\n",
    "        os.makedirs(shap_dir)\n",
    "\n",
    "    # Initialize variables\n",
    "    label_encoders = {}\n",
    "    df_encoded = df_clean.copy()\n",
    "    df_encoded = df_encoded.dropna(subset=[\"Sensitivity\"])\n",
    "    for col in df_encoded.columns:\n",
    "        if df_encoded[col].dtype == 'object' or df_encoded[col].dtype.name == 'category':\n",
    "            le = LabelEncoder()\n",
    "            df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "\n",
    "    models_results_rf_specific_drug_sensitivity = {}\n",
    "    cumulative_cm = np.array([[0, 0], [0, 0]])\n",
    "    all_fpr_test = []\n",
    "    all_precision_test = []\n",
    "    drug_names = []\n",
    "\n",
    "    y_true_total = []\n",
    "    y_pred_total = []\n",
    "\n",
    "    for specific_drug in tqdm(score_df[\"Drug\"].iloc[1:l], desc=\"Processing Drugs\"):\n",
    "        ## Model for each drug\n",
    "\n",
    "        df_drug = df_encoded[df_encoded[\"Drug_id\"] == specific_drug]\n",
    "        drug_name = score_df.loc[score_df[\"Drug\"] == specific_drug, \"Drug_name\"].values[0]\n",
    "\n",
    "        # Directory for the specific drug\n",
    "        models_dir = os.path.join(shap_dir, f\"{drug_name}_models\")\n",
    "        os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "        # Training and Test set\n",
    "        cell_counts = df_drug[\"Cell_line_cosmic_identifiers\"].value_counts()\n",
    "        train_cells, test_cells = train_test_split(\n",
    "            cell_counts.index,\n",
    "            test_size=0.2,\n",
    "            stratify=df_drug.groupby(\"Cell_line_cosmic_identifiers\")[\"Sensitivity\"].apply(lambda x: x.mean()),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        train_set = df_drug[df_drug[\"Cell_line_cosmic_identifiers\"].isin(train_cells)]\n",
    "        test_set = df_drug[df_drug[\"Cell_line_cosmic_identifiers\"].isin(test_cells)]\n",
    "\n",
    "        X_test = test_set.drop(columns=[\"IC50\", \"Sensitivity\", \"Cell_line_cosmic_identifiers\", \"Screened_Compounds_\", \"Sample_Names\", \"Drug_id\"])\n",
    "        y_test = test_set[\"Sensitivity\"]\n",
    "\n",
    "        # Train the models and save them\n",
    "        '''\n",
    "        models_per_fold, y_val_all, y_val_pred_all = modello_base(train_set, train_cells, rf_params, \n",
    "               base_models, param_grid, n_splits=5, random_state=42)\n",
    "        for fold_idx, model_info in enumerate(models_per_fold):\n",
    "            model_path = os.path.join(models_dir, f\"model_fold_{fold_idx}.pkl\")\n",
    "            joblib.dump(model_info, model_path)\n",
    "\n",
    "        '''\n",
    "\n",
    "        models_per_fold, y_val_all, y_val_pred_all = testing(train_set, train_cells, shap_dir, drug_name, n_splits=5, random_state=42)\n",
    "        # Predict final probability\n",
    "        avg_auc_score = np.mean([m[\"auc_score\"] for m in models_per_fold])\n",
    "        avg_auc_pr = np.mean([m[\"auc_pr\"] for m in models_per_fold])\n",
    "        avg_f1_score = np.mean([m[\"f1_score\"] for m in models_per_fold])\n",
    "        aucprs = np.array([m[\"auc_pr\"] for m in models_per_fold])\n",
    "        weights = aucprs / aucprs.sum()\n",
    "        y_pred_test_prob = sum(weights[i] * models_per_fold[i][\"model\"].predict_proba(X_test)[:, 1] for i in range(len(weights)))\n",
    "\n",
    "        #Calculate best threshol \n",
    "        precision_val, recall_val, thresholds = precision_recall_curve(y_val_all, y_val_pred_all)\n",
    "        f1_scores = 2 * (precision_val * recall_val) / (precision_val + recall_val + 1e-6)\n",
    "        best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        y_pred_test = (y_pred_test_prob > best_threshold).astype(int)\n",
    "\n",
    "        #Calculate metrics for the test\n",
    "        auc_score_test = roc_auc_score(y_test, y_pred_test_prob)\n",
    "        auc_pr_test = average_precision_score(y_test, y_pred_test_prob)\n",
    "        f1_test = f1_score(y_test, y_pred_test)\n",
    "        precision_test_val = precision_score(y_test, y_pred_test)\n",
    "        recall_test_val = recall_score(y_test, y_pred_test)\n",
    "\n",
    "        #Save all the metrics for the test\n",
    "        models_results_rf_specific_drug_sensitivity[drug_name] = {\n",
    "            \"avg_auc_score\": avg_auc_score,\n",
    "            \"avg_auc_pr\": avg_auc_pr,\n",
    "            \"avg_f1_score\": avg_f1_score,\n",
    "            \"auc_score_test\": auc_score_test,\n",
    "            \"auc_pr_test\": auc_pr_test,\n",
    "            \"f1_score_test\": f1_test,\n",
    "            \"best_threshold\": best_threshold,\n",
    "            \"precision_test\": precision_test_val,\n",
    "            \"recall_test\": recall_test_val\n",
    "        }\n",
    "\n",
    "        ## Generate plots\n",
    "        plots(y_test,\n",
    "            y_pred_test,\n",
    "            y_val_all,\n",
    "            y_val_pred_all,\n",
    "            shap_dir,\n",
    "            drug_name,\n",
    "            specific_drug,\n",
    "            y_pred_test_prob,\n",
    "            all_fpr_test,\n",
    "            all_precision_test,\n",
    "            drug_names,\n",
    "            recall_val,\n",
    "            precision_val,\n",
    "            avg_auc_score,\n",
    "            auc_score_test,\n",
    "            avg_auc_pr,\n",
    "            auc_pr_test,\n",
    "            best_threshold,\n",
    "            cumulative_cm\n",
    "        )\n",
    "\n",
    "        # SHAP and plots\n",
    "        generate_shap_plots(\n",
    "            models_per_fold,\n",
    "            X_test,\n",
    "            test_set,\n",
    "            df_clean,\n",
    "            shap_dir,\n",
    "            drug_name,\n",
    "            specific_drug\n",
    "        )\n",
    "\n",
    "    \n",
    "        # Print results (Not necessary)\n",
    "        print(f\"\\n **Results for {drug_name}** \")\n",
    "        print(f\"AUC-ROC Test: {auc_score_test:.3f}\")\n",
    "        print(f\"AUC-PR Test: {auc_pr_test:.3f}\")\n",
    "        print(f\"F1-score Test: {f1_test:.3f}\")\n",
    "\n",
    "        print(\"\\n **Validation Set Classification Report:**\")\n",
    "        print(classification_report(y_val_all, (np.array(y_val_pred_all) > 0.5).astype(int)))\n",
    "\n",
    "        print(\"\\n**Test Set Classification Report:**\")\n",
    "        print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "        y_true_total.extend(y_test)\n",
    "        y_pred_total.extend(y_pred_test)\n",
    "\n",
    "\n",
    "    # Print and Save Final results\n",
    "    print(\"\\n\\n========== RIASSUNTO FINALE ==========\")\n",
    "    \n",
    "    final_f1 = f1_score(y_true_total, y_pred_total)\n",
    "    results_df = pd.DataFrame.from_dict(models_results_rf_specific_drug_sensitivity, orient=\"index\")\n",
    "    results_df.to_csv(os.path.join(shap_dir, \"rf_drug_sensitivity_results.csv\"))\n",
    "\n",
    "    cm_fig_path = os.path.join(shap_dir, \"total_confusion_matrix.png\")\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cumulative_cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "    fig, ax = plt.subplots()\n",
    "    disp.plot(cmap=\"Purples\", ax=ax)\n",
    "    plt.title(f\"Confusion Matrix - TOTALE (Test Set)\\nF1-score Finale: {final_f1:.4f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    roc_all_fig_path = os.path.join(shap_dir, \"roc_curve_all_drugs.png\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, (fpr, tpr) in enumerate(all_fpr_test):\n",
    "        plt.plot(fpr, tpr, label=drug_names[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve - Tutti i farmaci\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(roc_all_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    pr_all_fig_path = os.path.join(shap_dir, \"precision_recall_curve_all_drugs.png\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, (recall, precision) in enumerate(all_precision_test):\n",
    "        plt.plot(recall, precision, label=drug_names[i])\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve - Tutti i farmaci\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(pr_all_fig_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcolo SHAP per KIN001-260 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   3%|▎         | 1/30 [00:35<17:23, 35.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for KIN001-260** \n",
      "AUC-ROC Test: 0.754\n",
      "AUC-PR Test: 0.597\n",
      "F1-score Test: 0.512\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.93      0.90       351\n",
      "         1.0       0.73      0.60      0.66       119\n",
      "\n",
      "    accuracy                           0.84       470\n",
      "   macro avg       0.80      0.76      0.78       470\n",
      "weighted avg       0.84      0.84      0.84       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89        93\n",
      "         1.0       0.65      0.42      0.51        26\n",
      "\n",
      "    accuracy                           0.82       119\n",
      "   macro avg       0.75      0.68      0.70       119\n",
      "weighted avg       0.81      0.82      0.81       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TG101348 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   7%|▋         | 2/30 [01:12<16:48, 36.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TG101348** \n",
      "AUC-ROC Test: 0.889\n",
      "AUC-PR Test: 0.651\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95       414\n",
      "         1.0       0.58      0.67      0.62        55\n",
      "\n",
      "    accuracy                           0.90       469\n",
      "   macro avg       0.77      0.80      0.78       469\n",
      "weighted avg       0.91      0.90      0.91       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.96       107\n",
      "         1.0       0.60      0.75      0.67        12\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.79      0.85      0.81       119\n",
      "weighted avg       0.93      0.92      0.93       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per BX-912 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  10%|█         | 3/30 [01:46<15:58, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for BX-912** \n",
      "AUC-ROC Test: 0.949\n",
      "AUC-PR Test: 0.752\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93       410\n",
      "         1.0       0.51      0.52      0.51        60\n",
      "\n",
      "    accuracy                           0.87       470\n",
      "   macro avg       0.72      0.72      0.72       470\n",
      "weighted avg       0.88      0.87      0.87       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.96       102\n",
      "         1.0       0.82      0.56      0.67        16\n",
      "\n",
      "    accuracy                           0.92       118\n",
      "   macro avg       0.88      0.77      0.81       118\n",
      "weighted avg       0.92      0.92      0.92       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per QL-XI-92 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  13%|█▎        | 4/30 [02:23<15:33, 35.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for QL-XI-92** \n",
      "AUC-ROC Test: 0.755\n",
      "AUC-PR Test: 0.632\n",
      "F1-score Test: 0.571\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.86      0.81       303\n",
      "         1.0       0.67      0.51      0.58       166\n",
      "\n",
      "    accuracy                           0.74       469\n",
      "   macro avg       0.71      0.68      0.69       469\n",
      "weighted avg       0.73      0.74      0.73       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.83      0.82        83\n",
      "         1.0       0.59      0.56      0.57        36\n",
      "\n",
      "    accuracy                           0.75       119\n",
      "   macro avg       0.70      0.69      0.70       119\n",
      "weighted avg       0.74      0.75      0.75       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Tubastatin A su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  17%|█▋        | 5/30 [02:56<14:35, 35.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Tubastatin A** \n",
      "AUC-ROC Test: 0.761\n",
      "AUC-PR Test: 0.654\n",
      "F1-score Test: 0.508\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.87      0.83       320\n",
      "         1.0       0.64      0.50      0.56       147\n",
      "\n",
      "    accuracy                           0.75       467\n",
      "   macro avg       0.72      0.68      0.69       467\n",
      "weighted avg       0.74      0.75      0.74       467\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.84      0.82        85\n",
      "         1.0       0.53      0.48      0.51        33\n",
      "\n",
      "    accuracy                           0.74       118\n",
      "   macro avg       0.67      0.66      0.66       118\n",
      "weighted avg       0.73      0.74      0.73       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK690693 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  20%|██        | 6/30 [03:28<13:36, 34.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK690693** \n",
      "AUC-ROC Test: 0.713\n",
      "AUC-PR Test: 0.685\n",
      "F1-score Test: 0.588\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.82      0.80       308\n",
      "         1.0       0.62      0.55      0.58       161\n",
      "\n",
      "    accuracy                           0.73       469\n",
      "   macro avg       0.70      0.69      0.69       469\n",
      "weighted avg       0.72      0.73      0.73       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.75      0.77        76\n",
      "         1.0       0.57      0.61      0.59        41\n",
      "\n",
      "    accuracy                           0.70       117\n",
      "   macro avg       0.67      0.68      0.68       117\n",
      "weighted avg       0.71      0.70      0.70       117\n",
      "\n",
      "\n",
      "Calcolo SHAP per XMD14-99 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  23%|██▎       | 7/30 [04:38<17:32, 45.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for XMD14-99** \n",
      "AUC-ROC Test: 0.874\n",
      "AUC-PR Test: 0.482\n",
      "F1-score Test: 0.485\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       784\n",
      "         1.0       0.70      0.64      0.67       154\n",
      "\n",
      "    accuracy                           0.90       938\n",
      "   macro avg       0.81      0.79      0.80       938\n",
      "weighted avg       0.89      0.90      0.89       938\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.92       208\n",
      "         1.0       0.44      0.53      0.48        30\n",
      "\n",
      "    accuracy                           0.86       238\n",
      "   macro avg       0.69      0.72      0.70       238\n",
      "weighted avg       0.87      0.86      0.86       238\n",
      "\n",
      "\n",
      "Calcolo SHAP per NPK76-II-72-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  27%|██▋       | 8/30 [05:13<15:31, 42.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for NPK76-II-72-1** \n",
      "AUC-ROC Test: 0.961\n",
      "AUC-PR Test: 0.744\n",
      "F1-score Test: 0.545\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95       430\n",
      "         1.0       0.50      0.57      0.53        40\n",
      "\n",
      "    accuracy                           0.91       470\n",
      "   macro avg       0.73      0.76      0.74       470\n",
      "weighted avg       0.92      0.91      0.92       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95       110\n",
      "         1.0       0.46      0.67      0.55         9\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.72      0.80      0.75       119\n",
      "weighted avg       0.93      0.92      0.92       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Y-39983 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  30%|███       | 9/30 [06:26<18:07, 51.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Y-39983** \n",
      "AUC-ROC Test: 0.822\n",
      "AUC-PR Test: 0.774\n",
      "F1-score Test: 0.651\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.87      0.80       590\n",
      "         1.0       0.70      0.51      0.59       352\n",
      "\n",
      "    accuracy                           0.73       942\n",
      "   macro avg       0.72      0.69      0.70       942\n",
      "weighted avg       0.73      0.73      0.72       942\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.61      0.71       150\n",
      "         1.0       0.54      0.81      0.65        86\n",
      "\n",
      "    accuracy                           0.68       236\n",
      "   macro avg       0.70      0.71      0.68       236\n",
      "weighted avg       0.74      0.68      0.69       236\n",
      "\n",
      "\n",
      "Calcolo SHAP per AT-7519 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  33%|███▎      | 10/30 [06:56<15:03, 45.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for AT-7519** \n",
      "AUC-ROC Test: 0.963\n",
      "AUC-PR Test: 0.374\n",
      "F1-score Test: 0.545\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97       435\n",
      "         1.0       0.55      0.68      0.61        31\n",
      "\n",
      "    accuracy                           0.94       466\n",
      "   macro avg       0.76      0.82      0.79       466\n",
      "weighted avg       0.95      0.94      0.94       466\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98       114\n",
      "         1.0       0.43      0.75      0.55         4\n",
      "\n",
      "    accuracy                           0.96       118\n",
      "   macro avg       0.71      0.86      0.76       118\n",
      "weighted avg       0.97      0.96      0.96       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per KIN001-236 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  37%|███▋      | 11/30 [07:26<12:46, 40.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for KIN001-236** \n",
      "AUC-ROC Test: 0.843\n",
      "AUC-PR Test: 0.619\n",
      "F1-score Test: 0.571\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94       414\n",
      "         1.0       0.56      0.66      0.61        56\n",
      "\n",
      "    accuracy                           0.90       470\n",
      "   macro avg       0.76      0.80      0.77       470\n",
      "weighted avg       0.91      0.90      0.90       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93       105\n",
      "         1.0       0.48      0.71      0.57        14\n",
      "\n",
      "    accuracy                           0.87       119\n",
      "   macro avg       0.72      0.80      0.75       119\n",
      "weighted avg       0.90      0.87      0.88       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TL-2-105 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  40%|████      | 12/30 [07:55<11:06, 37.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TL-2-105** \n",
      "AUC-ROC Test: 0.888\n",
      "AUC-PR Test: 0.732\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94       415\n",
      "         1.0       0.56      0.50      0.53        54\n",
      "\n",
      "    accuracy                           0.90       469\n",
      "   macro avg       0.75      0.72      0.74       469\n",
      "weighted avg       0.89      0.90      0.90       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.93        99\n",
      "         1.0       0.68      0.65      0.67        20\n",
      "\n",
      "    accuracy                           0.89       119\n",
      "   macro avg       0.81      0.79      0.80       119\n",
      "weighted avg       0.89      0.89      0.89       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per ABT-263 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  43%|████▎     | 13/30 [09:23<14:53, 52.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for ABT-263** \n",
      "AUC-ROC Test: 0.828\n",
      "AUC-PR Test: 0.671\n",
      "F1-score Test: 0.679\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89       966\n",
      "         1.0       0.66      0.59      0.62       303\n",
      "\n",
      "    accuracy                           0.83      1269\n",
      "   macro avg       0.77      0.75      0.76      1269\n",
      "weighted avg       0.82      0.83      0.83      1269\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88       234\n",
      "         1.0       0.68      0.68      0.68        84\n",
      "\n",
      "    accuracy                           0.83       318\n",
      "   macro avg       0.78      0.78      0.78       318\n",
      "weighted avg       0.83      0.83      0.83       318\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK1070916 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  47%|████▋     | 14/30 [09:53<12:10, 45.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK1070916** \n",
      "AUC-ROC Test: 0.939\n",
      "AUC-PR Test: 0.712\n",
      "F1-score Test: 0.700\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91       380\n",
      "         1.0       0.55      0.55      0.55        78\n",
      "\n",
      "    accuracy                           0.85       458\n",
      "   macro avg       0.73      0.73      0.73       458\n",
      "weighted avg       0.85      0.85      0.85       458\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.90      0.94       100\n",
      "         1.0       0.58      0.88      0.70        16\n",
      "\n",
      "    accuracy                           0.90       116\n",
      "   macro avg       0.78      0.89      0.82       116\n",
      "weighted avg       0.92      0.90      0.90       116\n",
      "\n",
      "\n",
      "Calcolo SHAP per Methotrexate su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  50%|█████     | 15/30 [10:22<10:06, 40.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Methotrexate** \n",
      "AUC-ROC Test: 0.812\n",
      "AUC-PR Test: 0.382\n",
      "F1-score Test: 0.583\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.92       355\n",
      "         1.0       0.59      0.68      0.64        69\n",
      "\n",
      "    accuracy                           0.87       424\n",
      "   macro avg       0.77      0.80      0.78       424\n",
      "weighted avg       0.88      0.87      0.88       424\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.92      0.95        97\n",
      "         1.0       0.47      0.78      0.58         9\n",
      "\n",
      "    accuracy                           0.91       106\n",
      "   macro avg       0.72      0.85      0.77       106\n",
      "weighted avg       0.93      0.91      0.92       106\n",
      "\n",
      "\n",
      "Calcolo SHAP per TL-1-85 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  53%|█████▎    | 16/30 [10:54<08:53, 38.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TL-1-85** \n",
      "AUC-ROC Test: 0.947\n",
      "AUC-PR Test: 0.631\n",
      "F1-score Test: 0.645\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.96       435\n",
      "         1.0       0.53      0.74      0.62        35\n",
      "\n",
      "    accuracy                           0.93       470\n",
      "   macro avg       0.75      0.84      0.79       470\n",
      "weighted avg       0.95      0.93      0.94       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95       104\n",
      "         1.0       0.62      0.67      0.65        15\n",
      "\n",
      "    accuracy                           0.91       119\n",
      "   macro avg       0.79      0.80      0.80       119\n",
      "weighted avg       0.91      0.91      0.91       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per T0901317 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  57%|█████▋    | 17/30 [12:00<10:03, 46.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for T0901317** \n",
      "AUC-ROC Test: 0.882\n",
      "AUC-PR Test: 0.618\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95       814\n",
      "         1.0       0.62      0.68      0.65       118\n",
      "\n",
      "    accuracy                           0.91       932\n",
      "   macro avg       0.78      0.81      0.80       932\n",
      "weighted avg       0.91      0.91      0.91       932\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96       206\n",
      "         1.0       0.75      0.60      0.67        30\n",
      "\n",
      "    accuracy                           0.92       236\n",
      "   macro avg       0.85      0.79      0.81       236\n",
      "weighted avg       0.92      0.92      0.92       236\n",
      "\n",
      "\n",
      "Calcolo SHAP per PHA-793887 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  60%|██████    | 18/30 [12:35<08:37, 43.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for PHA-793887** \n",
      "AUC-ROC Test: 0.979\n",
      "AUC-PR Test: 0.690\n",
      "F1-score Test: 0.545\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.92      0.93       414\n",
      "         1.0       0.47      0.53      0.50        55\n",
      "\n",
      "    accuracy                           0.87       469\n",
      "   macro avg       0.70      0.72      0.71       469\n",
      "weighted avg       0.88      0.87      0.88       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.91      0.95       113\n",
      "         1.0       0.38      1.00      0.55         6\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.69      0.96      0.75       119\n",
      "weighted avg       0.97      0.92      0.93       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per JW-7-24-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  63%|██████▎   | 19/30 [13:11<07:29, 40.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for JW-7-24-1** \n",
      "AUC-ROC Test: 0.904\n",
      "AUC-PR Test: 0.550\n",
      "F1-score Test: 0.619\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       417\n",
      "         1.0       0.61      0.63      0.62        52\n",
      "\n",
      "    accuracy                           0.91       469\n",
      "   macro avg       0.78      0.79      0.79       469\n",
      "weighted avg       0.92      0.91      0.92       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.87      0.92       103\n",
      "         1.0       0.50      0.81      0.62        16\n",
      "\n",
      "    accuracy                           0.87       119\n",
      "   macro avg       0.73      0.84      0.77       119\n",
      "weighted avg       0.90      0.87      0.88       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TPCA-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  67%|██████▋   | 20/30 [13:40<06:13, 37.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TPCA-1** \n",
      "AUC-ROC Test: 0.950\n",
      "AUC-PR Test: 0.691\n",
      "F1-score Test: 0.545\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95       425\n",
      "         1.0       0.54      0.64      0.59        45\n",
      "\n",
      "    accuracy                           0.91       470\n",
      "   macro avg       0.75      0.79      0.77       470\n",
      "weighted avg       0.92      0.91      0.92       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       108\n",
      "         1.0       0.55      0.55      0.55        11\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.75      0.75      0.75       119\n",
      "weighted avg       0.92      0.92      0.92       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per CX-5461 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  70%|███████   | 21/30 [14:10<05:14, 34.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for CX-5461** \n",
      "AUC-ROC Test: 0.636\n",
      "AUC-PR Test: 0.735\n",
      "F1-score Test: 0.700\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.73      0.65       208\n",
      "         1.0       0.73      0.58      0.65       260\n",
      "\n",
      "    accuracy                           0.65       468\n",
      "   macro avg       0.65      0.65      0.65       468\n",
      "weighted avg       0.66      0.65      0.65       468\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.55      0.95      0.70        66\n",
      "\n",
      "    accuracy                           0.54       117\n",
      "   macro avg       0.28      0.48      0.35       117\n",
      "weighted avg       0.31      0.54      0.39       117\n",
      "\n",
      "\n",
      "Calcolo SHAP per STF-62247 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  73%|███████▎  | 22/30 [14:41<04:30, 33.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for STF-62247** \n",
      "AUC-ROC Test: 0.770\n",
      "AUC-PR Test: 0.520\n",
      "F1-score Test: 0.541\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.93      0.93       394\n",
      "         1.0       0.62      0.59      0.61        73\n",
      "\n",
      "    accuracy                           0.88       467\n",
      "   macro avg       0.77      0.76      0.77       467\n",
      "weighted avg       0.88      0.88      0.88       467\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.94      0.91        97\n",
      "         1.0       0.62      0.48      0.54        21\n",
      "\n",
      "    accuracy                           0.86       118\n",
      "   macro avg       0.76      0.71      0.73       118\n",
      "weighted avg       0.84      0.86      0.85       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per Dabrafenib su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  77%|███████▋  | 23/30 [15:09<03:44, 32.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Dabrafenib** \n",
      "AUC-ROC Test: 0.651\n",
      "AUC-PR Test: 0.233\n",
      "F1-score Test: 0.294\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.89      0.90       366\n",
      "         1.0       0.53      0.58      0.55        78\n",
      "\n",
      "    accuracy                           0.84       444\n",
      "   macro avg       0.72      0.73      0.73       444\n",
      "weighted avg       0.84      0.84      0.84       444\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.85      0.87        96\n",
      "         1.0       0.26      0.33      0.29        15\n",
      "\n",
      "    accuracy                           0.78       111\n",
      "   macro avg       0.58      0.59      0.58       111\n",
      "weighted avg       0.81      0.78      0.79       111\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK429286A su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  80%|████████  | 24/30 [15:39<03:08, 31.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK429286A** \n",
      "AUC-ROC Test: 0.894\n",
      "AUC-PR Test: 0.692\n",
      "F1-score Test: 0.650\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.94       416\n",
      "         1.0       0.49      0.38      0.43        53\n",
      "\n",
      "    accuracy                           0.88       469\n",
      "   macro avg       0.71      0.66      0.68       469\n",
      "weighted avg       0.87      0.88      0.88       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.92      0.93       100\n",
      "         1.0       0.62      0.68      0.65        19\n",
      "\n",
      "    accuracy                           0.88       119\n",
      "   macro avg       0.78      0.80      0.79       119\n",
      "weighted avg       0.89      0.88      0.88       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Trametinib su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  83%|████████▎ | 25/30 [16:09<02:35, 31.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Trametinib** \n",
      "AUC-ROC Test: 0.786\n",
      "AUC-PR Test: 0.621\n",
      "F1-score Test: 0.622\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.74      0.77       305\n",
      "         1.0       0.52      0.58      0.55       146\n",
      "\n",
      "    accuracy                           0.69       451\n",
      "   macro avg       0.65      0.66      0.66       451\n",
      "weighted avg       0.70      0.69      0.70       451\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.69      0.75        75\n",
      "         1.0       0.55      0.72      0.62        39\n",
      "\n",
      "    accuracy                           0.70       114\n",
      "   macro avg       0.69      0.71      0.69       114\n",
      "weighted avg       0.73      0.70      0.71       114\n",
      "\n",
      "\n",
      "Calcolo SHAP per NG-25 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  87%|████████▋ | 26/30 [16:39<02:03, 30.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for NG-25** \n",
      "AUC-ROC Test: 0.933\n",
      "AUC-PR Test: 0.660\n",
      "F1-score Test: 0.640\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95       428\n",
      "         1.0       0.48      0.60      0.53        42\n",
      "\n",
      "    accuracy                           0.91       470\n",
      "   macro avg       0.72      0.77      0.74       470\n",
      "weighted avg       0.92      0.91      0.91       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96       105\n",
      "         1.0       0.73      0.57      0.64        14\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.84      0.77      0.80       119\n",
      "weighted avg       0.92      0.92      0.92       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per BIX02189 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  90%|█████████ | 27/30 [17:10<01:32, 30.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for BIX02189** \n",
      "AUC-ROC Test: 0.942\n",
      "AUC-PR Test: 0.699\n",
      "F1-score Test: 0.824\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95       429\n",
      "         1.0       0.49      0.61      0.54        41\n",
      "\n",
      "    accuracy                           0.91       470\n",
      "   macro avg       0.73      0.77      0.75       470\n",
      "weighted avg       0.92      0.91      0.91       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97       103\n",
      "         1.0       0.78      0.88      0.82        16\n",
      "\n",
      "    accuracy                           0.95       119\n",
      "   macro avg       0.88      0.92      0.90       119\n",
      "weighted avg       0.95      0.95      0.95       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per PIK-93 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  93%|█████████▎| 28/30 [18:11<01:19, 39.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for PIK-93** \n",
      "AUC-ROC Test: 0.843\n",
      "AUC-PR Test: 0.754\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93       804\n",
      "         1.0       0.60      0.65      0.62       136\n",
      "\n",
      "    accuracy                           0.89       940\n",
      "   macro avg       0.77      0.79      0.78       940\n",
      "weighted avg       0.89      0.89      0.89       940\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.96       212\n",
      "         1.0       0.64      0.69      0.67        26\n",
      "\n",
      "    accuracy                           0.92       238\n",
      "   macro avg       0.80      0.82      0.81       238\n",
      "weighted avg       0.93      0.92      0.93       238\n",
      "\n",
      "\n",
      "Calcolo SHAP per XMD15-27 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  97%|█████████▋| 29/30 [20:38<01:11, 71.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for XMD15-27** \n",
      "AUC-ROC Test: 0.956\n",
      "AUC-PR Test: 0.856\n",
      "F1-score Test: 0.757\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94      2045\n",
      "         1.0       0.58      0.57      0.57       300\n",
      "\n",
      "    accuracy                           0.89      2345\n",
      "   macro avg       0.76      0.75      0.75      2345\n",
      "weighted avg       0.89      0.89      0.89      2345\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.96       515\n",
      "         1.0       0.67      0.88      0.76        80\n",
      "\n",
      "    accuracy                           0.92       595\n",
      "   macro avg       0.82      0.90      0.86       595\n",
      "weighted avg       0.94      0.92      0.93       595\n",
      "\n",
      "\n",
      "Calcolo SHAP per AC220 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs: 100%|██████████| 30/30 [21:07<00:00, 42.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for AC220** \n",
      "AUC-ROC Test: 0.832\n",
      "AUC-PR Test: 0.469\n",
      "F1-score Test: 0.357\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.89      0.90       397\n",
      "         1.0       0.47      0.54      0.50        72\n",
      "\n",
      "    accuracy                           0.84       469\n",
      "   macro avg       0.69      0.72      0.70       469\n",
      "weighted avg       0.85      0.84      0.84       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.92      0.91       104\n",
      "         1.0       0.38      0.33      0.36        15\n",
      "\n",
      "    accuracy                           0.85       119\n",
      "   macro avg       0.65      0.63      0.64       119\n",
      "weighted avg       0.84      0.85      0.84       119\n",
      "\n",
      "\n",
      "\n",
      "========== RIASSUNTO FINALE ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Seed\n",
    "rf_params = {\n",
    "        \"random_state\": 1,\n",
    "    }\n",
    "\n",
    "# Param grid space for Hyperparameter Tuning (it can be changed)\n",
    "param_grid = {\n",
    "    \"n_estimators\": randint(10, 501),              \n",
    "    \"max_depth\": [5, 7, 10, 20, None],\n",
    "    \"min_samples_split\": randint(2, 11),\n",
    "    \"min_samples_leaf\": randint(1, 6),\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# Directory to save the results\n",
    "dir = 'Results/Models_Sensitivity/RF'\n",
    "\n",
    "# Run the function\n",
    "train_model(df_clean, rf_params, None, param_grid, dir, l=31) #if you want more drugs to be evaluated, increase l."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcolo SHAP per KIN001-260 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   3%|▎         | 1/30 [00:25<12:27, 25.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for KIN001-260** \n",
      "AUC-ROC Test: 0.734\n",
      "AUC-PR Test: 0.597\n",
      "F1-score Test: 0.489\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.90      0.88       351\n",
      "         1.0       0.67      0.60      0.63       119\n",
      "\n",
      "    accuracy                           0.82       470\n",
      "   macro avg       0.77      0.75      0.76       470\n",
      "weighted avg       0.82      0.82      0.82       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.91      0.88        93\n",
      "         1.0       0.58      0.42      0.49        26\n",
      "\n",
      "    accuracy                           0.81       119\n",
      "   macro avg       0.71      0.67      0.68       119\n",
      "weighted avg       0.79      0.81      0.80       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TG101348 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   7%|▋         | 2/30 [00:50<11:48, 25.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TG101348** \n",
      "AUC-ROC Test: 0.953\n",
      "AUC-PR Test: 0.551\n",
      "F1-score Test: 0.714\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93       414\n",
      "         1.0       0.50      0.65      0.57        55\n",
      "\n",
      "    accuracy                           0.88       469\n",
      "   macro avg       0.73      0.78      0.75       469\n",
      "weighted avg       0.90      0.88      0.89       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.94      0.96       107\n",
      "         1.0       0.62      0.83      0.71        12\n",
      "\n",
      "    accuracy                           0.93       119\n",
      "   macro avg       0.80      0.89      0.84       119\n",
      "weighted avg       0.94      0.93      0.94       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per BX-912 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  10%|█         | 3/30 [01:16<11:27, 25.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for BX-912** \n",
      "AUC-ROC Test: 0.924\n",
      "AUC-PR Test: 0.678\n",
      "F1-score Test: 0.645\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90       410\n",
      "         1.0       0.39      0.58      0.47        60\n",
      "\n",
      "    accuracy                           0.83       470\n",
      "   macro avg       0.66      0.73      0.68       470\n",
      "weighted avg       0.87      0.83      0.85       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95       102\n",
      "         1.0       0.67      0.62      0.65        16\n",
      "\n",
      "    accuracy                           0.91       118\n",
      "   macro avg       0.80      0.79      0.80       118\n",
      "weighted avg       0.90      0.91      0.91       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per QL-XI-92 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  13%|█▎        | 4/30 [01:43<11:14, 25.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for QL-XI-92** \n",
      "AUC-ROC Test: 0.718\n",
      "AUC-PR Test: 0.583\n",
      "F1-score Test: 0.559\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.80      0.79       303\n",
      "         1.0       0.61      0.60      0.61       166\n",
      "\n",
      "    accuracy                           0.72       469\n",
      "   macro avg       0.70      0.70      0.70       469\n",
      "weighted avg       0.72      0.72      0.72       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.84      0.82        83\n",
      "         1.0       0.59      0.53      0.56        36\n",
      "\n",
      "    accuracy                           0.75       119\n",
      "   macro avg       0.70      0.69      0.69       119\n",
      "weighted avg       0.74      0.75      0.74       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Tubastatin A su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  17%|█▋        | 5/30 [02:10<11:01, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Tubastatin A** \n",
      "AUC-ROC Test: 0.737\n",
      "AUC-PR Test: 0.633\n",
      "F1-score Test: 0.481\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.81      0.81       320\n",
      "         1.0       0.58      0.56      0.57       147\n",
      "\n",
      "    accuracy                           0.73       467\n",
      "   macro avg       0.69      0.69      0.69       467\n",
      "weighted avg       0.73      0.73      0.73       467\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.91      0.85        85\n",
      "         1.0       0.62      0.39      0.48        33\n",
      "\n",
      "    accuracy                           0.76       118\n",
      "   macro avg       0.71      0.65      0.66       118\n",
      "weighted avg       0.74      0.76      0.74       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK690693 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  20%|██        | 6/30 [02:30<09:44, 24.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK690693** \n",
      "AUC-ROC Test: 0.697\n",
      "AUC-PR Test: 0.626\n",
      "F1-score Test: 0.522\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.80      0.79       308\n",
      "         1.0       0.59      0.57      0.58       161\n",
      "\n",
      "    accuracy                           0.72       469\n",
      "   macro avg       0.68      0.68      0.68       469\n",
      "weighted avg       0.71      0.72      0.71       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.87      0.80        76\n",
      "         1.0       0.64      0.44      0.52        41\n",
      "\n",
      "    accuracy                           0.72       117\n",
      "   macro avg       0.69      0.65      0.66       117\n",
      "weighted avg       0.71      0.72      0.70       117\n",
      "\n",
      "\n",
      "Calcolo SHAP per XMD14-99 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  23%|██▎       | 7/30 [03:20<12:29, 32.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for XMD14-99** \n",
      "AUC-ROC Test: 0.867\n",
      "AUC-PR Test: 0.443\n",
      "F1-score Test: 0.444\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94       784\n",
      "         1.0       0.68      0.65      0.66       154\n",
      "\n",
      "    accuracy                           0.89       938\n",
      "   macro avg       0.80      0.79      0.80       938\n",
      "weighted avg       0.89      0.89      0.89       938\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.88      0.90       208\n",
      "         1.0       0.38      0.53      0.44        30\n",
      "\n",
      "    accuracy                           0.83       238\n",
      "   macro avg       0.65      0.70      0.67       238\n",
      "weighted avg       0.86      0.83      0.84       238\n",
      "\n",
      "\n",
      "Calcolo SHAP per NPK76-II-72-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  27%|██▋       | 8/30 [03:47<11:17, 30.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for NPK76-II-72-1** \n",
      "AUC-ROC Test: 0.965\n",
      "AUC-PR Test: 0.748\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.94       430\n",
      "         1.0       0.43      0.65      0.51        40\n",
      "\n",
      "    accuracy                           0.90       470\n",
      "   macro avg       0.70      0.78      0.73       470\n",
      "weighted avg       0.92      0.90      0.91       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       110\n",
      "         1.0       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.95       119\n",
      "   macro avg       0.82      0.82      0.82       119\n",
      "weighted avg       0.95      0.95      0.95       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Y-39983 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  30%|███       | 9/30 [04:38<13:03, 37.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Y-39983** \n",
      "AUC-ROC Test: 0.735\n",
      "AUC-PR Test: 0.715\n",
      "F1-score Test: 0.633\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.79       590\n",
      "         1.0       0.66      0.56      0.61       352\n",
      "\n",
      "    accuracy                           0.73       942\n",
      "   macro avg       0.71      0.69      0.70       942\n",
      "weighted avg       0.72      0.73      0.72       942\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.85      0.82       150\n",
      "         1.0       0.69      0.58      0.63        86\n",
      "\n",
      "    accuracy                           0.75       236\n",
      "   macro avg       0.74      0.72      0.72       236\n",
      "weighted avg       0.75      0.75      0.75       236\n",
      "\n",
      "\n",
      "Calcolo SHAP per AT-7519 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  33%|███▎      | 10/30 [05:06<11:24, 34.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for AT-7519** \n",
      "AUC-ROC Test: 0.967\n",
      "AUC-PR Test: 0.583\n",
      "F1-score Test: 0.333\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97       435\n",
      "         1.0       0.55      0.84      0.67        31\n",
      "\n",
      "    accuracy                           0.94       466\n",
      "   macro avg       0.77      0.90      0.82       466\n",
      "weighted avg       0.96      0.94      0.95       466\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       114\n",
      "         1.0       0.50      0.25      0.33         4\n",
      "\n",
      "    accuracy                           0.97       118\n",
      "   macro avg       0.74      0.62      0.66       118\n",
      "weighted avg       0.96      0.97      0.96       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per KIN001-236 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  37%|███▋      | 11/30 [05:32<10:03, 31.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for KIN001-236** \n",
      "AUC-ROC Test: 0.824\n",
      "AUC-PR Test: 0.622\n",
      "F1-score Test: 0.621\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94       414\n",
      "         1.0       0.54      0.71      0.62        56\n",
      "\n",
      "    accuracy                           0.89       470\n",
      "   macro avg       0.75      0.82      0.78       470\n",
      "weighted avg       0.91      0.89      0.90       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95       105\n",
      "         1.0       0.60      0.64      0.62        14\n",
      "\n",
      "    accuracy                           0.91       119\n",
      "   macro avg       0.78      0.79      0.78       119\n",
      "weighted avg       0.91      0.91      0.91       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TL-2-105 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  40%|████      | 12/30 [06:00<09:10, 30.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TL-2-105** \n",
      "AUC-ROC Test: 0.886\n",
      "AUC-PR Test: 0.729\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.93       415\n",
      "         1.0       0.45      0.50      0.47        54\n",
      "\n",
      "    accuracy                           0.87       469\n",
      "   macro avg       0.69      0.71      0.70       469\n",
      "weighted avg       0.88      0.87      0.87       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.96      0.94        99\n",
      "         1.0       0.75      0.60      0.67        20\n",
      "\n",
      "    accuracy                           0.90       119\n",
      "   macro avg       0.84      0.78      0.80       119\n",
      "weighted avg       0.89      0.90      0.89       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per ABT-263 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  43%|████▎     | 13/30 [07:09<12:00, 42.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for ABT-263** \n",
      "AUC-ROC Test: 0.812\n",
      "AUC-PR Test: 0.707\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.92      0.89       966\n",
      "         1.0       0.67      0.55      0.61       303\n",
      "\n",
      "    accuracy                           0.83      1269\n",
      "   macro avg       0.77      0.74      0.75      1269\n",
      "weighted avg       0.82      0.83      0.82      1269\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.85      0.87       234\n",
      "         1.0       0.62      0.71      0.67        84\n",
      "\n",
      "    accuracy                           0.81       318\n",
      "   macro avg       0.76      0.78      0.77       318\n",
      "weighted avg       0.82      0.81      0.82       318\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK1070916 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  47%|████▋     | 14/30 [07:42<10:28, 39.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK1070916** \n",
      "AUC-ROC Test: 0.923\n",
      "AUC-PR Test: 0.741\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91       380\n",
      "         1.0       0.56      0.59      0.57        78\n",
      "\n",
      "    accuracy                           0.85       458\n",
      "   macro avg       0.74      0.75      0.74       458\n",
      "weighted avg       0.85      0.85      0.85       458\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.94       100\n",
      "         1.0       0.65      0.69      0.67        16\n",
      "\n",
      "    accuracy                           0.91       116\n",
      "   macro avg       0.80      0.81      0.81       116\n",
      "weighted avg       0.91      0.91      0.91       116\n",
      "\n",
      "\n",
      "Calcolo SHAP per Methotrexate su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  50%|█████     | 15/30 [08:08<08:52, 35.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Methotrexate** \n",
      "AUC-ROC Test: 0.806\n",
      "AUC-PR Test: 0.421\n",
      "F1-score Test: 0.545\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.92       355\n",
      "         1.0       0.57      0.67      0.61        69\n",
      "\n",
      "    accuracy                           0.86       424\n",
      "   macro avg       0.75      0.78      0.77       424\n",
      "weighted avg       0.87      0.86      0.87       424\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95        97\n",
      "         1.0       0.46      0.67      0.55         9\n",
      "\n",
      "    accuracy                           0.91       106\n",
      "   macro avg       0.71      0.80      0.75       106\n",
      "weighted avg       0.92      0.91      0.91       106\n",
      "\n",
      "\n",
      "Calcolo SHAP per TL-1-85 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  53%|█████▎    | 16/30 [08:37<07:48, 33.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TL-1-85** \n",
      "AUC-ROC Test: 0.915\n",
      "AUC-PR Test: 0.494\n",
      "F1-score Test: 0.571\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.96       435\n",
      "         1.0       0.49      0.69      0.57        35\n",
      "\n",
      "    accuracy                           0.92       470\n",
      "   macro avg       0.73      0.81      0.76       470\n",
      "weighted avg       0.94      0.92      0.93       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       104\n",
      "         1.0       0.62      0.53      0.57        15\n",
      "\n",
      "    accuracy                           0.90       119\n",
      "   macro avg       0.77      0.74      0.76       119\n",
      "weighted avg       0.89      0.90      0.90       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per T0901317 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  57%|█████▋    | 17/30 [09:30<08:31, 39.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for T0901317** \n",
      "AUC-ROC Test: 0.873\n",
      "AUC-PR Test: 0.711\n",
      "F1-score Test: 0.571\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.92      0.93       814\n",
      "         1.0       0.55      0.69      0.61       118\n",
      "\n",
      "    accuracy                           0.89       932\n",
      "   macro avg       0.75      0.81      0.77       932\n",
      "weighted avg       0.90      0.89      0.89       932\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       206\n",
      "         1.0       0.62      0.53      0.57        30\n",
      "\n",
      "    accuracy                           0.90       236\n",
      "   macro avg       0.77      0.74      0.76       236\n",
      "weighted avg       0.89      0.90      0.90       236\n",
      "\n",
      "\n",
      "Calcolo SHAP per PHA-793887 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  60%|██████    | 18/30 [09:59<07:14, 36.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for PHA-793887** \n",
      "AUC-ROC Test: 0.966\n",
      "AUC-PR Test: 0.477\n",
      "F1-score Test: 0.556\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.90      0.92       414\n",
      "         1.0       0.46      0.62      0.53        55\n",
      "\n",
      "    accuracy                           0.87       469\n",
      "   macro avg       0.70      0.76      0.73       469\n",
      "weighted avg       0.89      0.87      0.88       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.96       113\n",
      "         1.0       0.42      0.83      0.56         6\n",
      "\n",
      "    accuracy                           0.93       119\n",
      "   macro avg       0.70      0.89      0.76       119\n",
      "weighted avg       0.96      0.93      0.94       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per JW-7-24-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  63%|██████▎   | 19/30 [10:29<06:17, 34.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for JW-7-24-1** \n",
      "AUC-ROC Test: 0.897\n",
      "AUC-PR Test: 0.483\n",
      "F1-score Test: 0.541\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95       417\n",
      "         1.0       0.57      0.62      0.59        52\n",
      "\n",
      "    accuracy                           0.91       469\n",
      "   macro avg       0.76      0.78      0.77       469\n",
      "weighted avg       0.91      0.91      0.91       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.89      0.92       103\n",
      "         1.0       0.48      0.62      0.54        16\n",
      "\n",
      "    accuracy                           0.86       119\n",
      "   macro avg       0.71      0.76      0.73       119\n",
      "weighted avg       0.88      0.86      0.87       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TPCA-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  67%|██████▋   | 20/30 [10:57<05:24, 32.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TPCA-1** \n",
      "AUC-ROC Test: 0.941\n",
      "AUC-PR Test: 0.598\n",
      "F1-score Test: 0.519\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95       425\n",
      "         1.0       0.50      0.56      0.53        45\n",
      "\n",
      "    accuracy                           0.90       470\n",
      "   macro avg       0.73      0.75      0.74       470\n",
      "weighted avg       0.91      0.90      0.91       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.92      0.94       108\n",
      "         1.0       0.44      0.64      0.52        11\n",
      "\n",
      "    accuracy                           0.89       119\n",
      "   macro avg       0.70      0.78      0.73       119\n",
      "weighted avg       0.91      0.89      0.90       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per CX-5461 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  70%|███████   | 21/30 [11:25<04:40, 31.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for CX-5461** \n",
      "AUC-ROC Test: 0.701\n",
      "AUC-PR Test: 0.773\n",
      "F1-score Test: 0.729\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.66      0.63       208\n",
      "         1.0       0.71      0.65      0.67       260\n",
      "\n",
      "    accuracy                           0.65       468\n",
      "   macro avg       0.65      0.65      0.65       468\n",
      "weighted avg       0.66      0.65      0.65       468\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.04      0.08        51\n",
      "         1.0       0.57      1.00      0.73        66\n",
      "\n",
      "    accuracy                           0.58       117\n",
      "   macro avg       0.79      0.52      0.40       117\n",
      "weighted avg       0.76      0.58      0.44       117\n",
      "\n",
      "\n",
      "Calcolo SHAP per STF-62247 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  73%|███████▎  | 22/30 [11:51<03:55, 29.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for STF-62247** \n",
      "AUC-ROC Test: 0.780\n",
      "AUC-PR Test: 0.583\n",
      "F1-score Test: 0.514\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.91      0.91       394\n",
      "         1.0       0.53      0.55      0.54        73\n",
      "\n",
      "    accuracy                           0.85       467\n",
      "   macro avg       0.72      0.73      0.73       467\n",
      "weighted avg       0.86      0.85      0.86       467\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.95      0.92        97\n",
      "         1.0       0.64      0.43      0.51        21\n",
      "\n",
      "    accuracy                           0.86       118\n",
      "   macro avg       0.76      0.69      0.71       118\n",
      "weighted avg       0.84      0.86      0.84       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per Dabrafenib su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  77%|███████▋  | 23/30 [12:10<03:04, 26.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Dabrafenib** \n",
      "AUC-ROC Test: 0.695\n",
      "AUC-PR Test: 0.307\n",
      "F1-score Test: 0.323\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.89      0.90       366\n",
      "         1.0       0.53      0.58      0.55        78\n",
      "\n",
      "    accuracy                           0.84       444\n",
      "   macro avg       0.72      0.73      0.73       444\n",
      "weighted avg       0.84      0.84      0.84       444\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89        96\n",
      "         1.0       0.31      0.33      0.32        15\n",
      "\n",
      "    accuracy                           0.81       111\n",
      "   macro avg       0.60      0.61      0.61       111\n",
      "weighted avg       0.82      0.81      0.81       111\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK429286A su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  80%|████████  | 24/30 [12:31<02:28, 24.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK429286A** \n",
      "AUC-ROC Test: 0.866\n",
      "AUC-PR Test: 0.654\n",
      "F1-score Test: 0.606\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.92       416\n",
      "         1.0       0.38      0.45      0.41        53\n",
      "\n",
      "    accuracy                           0.85       469\n",
      "   macro avg       0.65      0.68      0.66       469\n",
      "weighted avg       0.87      0.85      0.86       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.94       100\n",
      "         1.0       0.71      0.53      0.61        19\n",
      "\n",
      "    accuracy                           0.89       119\n",
      "   macro avg       0.81      0.74      0.77       119\n",
      "weighted avg       0.88      0.89      0.88       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Trametinib su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  83%|████████▎ | 25/30 [12:58<02:07, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Trametinib** \n",
      "AUC-ROC Test: 0.781\n",
      "AUC-PR Test: 0.692\n",
      "F1-score Test: 0.598\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.81      0.80       305\n",
      "         1.0       0.59      0.58      0.58       146\n",
      "\n",
      "    accuracy                           0.73       451\n",
      "   macro avg       0.69      0.69      0.69       451\n",
      "weighted avg       0.73      0.73      0.73       451\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.52      0.64        75\n",
      "         1.0       0.47      0.82      0.60        39\n",
      "\n",
      "    accuracy                           0.62       114\n",
      "   macro avg       0.66      0.67      0.62       114\n",
      "weighted avg       0.72      0.62      0.63       114\n",
      "\n",
      "\n",
      "Calcolo SHAP per NG-25 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  87%|████████▋ | 26/30 [13:31<01:50, 27.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for NG-25** \n",
      "AUC-ROC Test: 0.847\n",
      "AUC-PR Test: 0.549\n",
      "F1-score Test: 0.640\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95       428\n",
      "         1.0       0.49      0.60      0.54        42\n",
      "\n",
      "    accuracy                           0.91       470\n",
      "   macro avg       0.72      0.77      0.74       470\n",
      "weighted avg       0.92      0.91      0.91       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96       105\n",
      "         1.0       0.73      0.57      0.64        14\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.84      0.77      0.80       119\n",
      "weighted avg       0.92      0.92      0.92       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per BIX02189 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  90%|█████████ | 27/30 [13:59<01:23, 27.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for BIX02189** \n",
      "AUC-ROC Test: 0.942\n",
      "AUC-PR Test: 0.685\n",
      "F1-score Test: 0.593\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.95       429\n",
      "         1.0       0.46      0.61      0.53        41\n",
      "\n",
      "    accuracy                           0.90       470\n",
      "   macro avg       0.71      0.77      0.74       470\n",
      "weighted avg       0.92      0.90      0.91       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95       103\n",
      "         1.0       0.73      0.50      0.59        16\n",
      "\n",
      "    accuracy                           0.91       119\n",
      "   macro avg       0.83      0.74      0.77       119\n",
      "weighted avg       0.90      0.91      0.90       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per PIK-93 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  93%|█████████▎| 28/30 [14:53<01:11, 35.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for PIK-93** \n",
      "AUC-ROC Test: 0.806\n",
      "AUC-PR Test: 0.597\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.92      0.93       804\n",
      "         1.0       0.58      0.67      0.62       136\n",
      "\n",
      "    accuracy                           0.88       940\n",
      "   macro avg       0.76      0.79      0.77       940\n",
      "weighted avg       0.89      0.88      0.88       940\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.96       212\n",
      "         1.0       0.64      0.69      0.67        26\n",
      "\n",
      "    accuracy                           0.92       238\n",
      "   macro avg       0.80      0.82      0.81       238\n",
      "weighted avg       0.93      0.92      0.93       238\n",
      "\n",
      "\n",
      "Calcolo SHAP per XMD15-27 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  97%|█████████▋| 29/30 [16:56<01:01, 61.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for XMD15-27** \n",
      "AUC-ROC Test: 0.954\n",
      "AUC-PR Test: 0.857\n",
      "F1-score Test: 0.759\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.92      2045\n",
      "         1.0       0.44      0.52      0.48       300\n",
      "\n",
      "    accuracy                           0.86      2345\n",
      "   macro avg       0.69      0.71      0.70      2345\n",
      "weighted avg       0.87      0.86      0.86      2345\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97       515\n",
      "         1.0       0.85      0.69      0.76        80\n",
      "\n",
      "    accuracy                           0.94       595\n",
      "   macro avg       0.90      0.83      0.86       595\n",
      "weighted avg       0.94      0.94      0.94       595\n",
      "\n",
      "\n",
      "Calcolo SHAP per AC220 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs: 100%|██████████| 30/30 [17:24<00:00, 34.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for AC220** \n",
      "AUC-ROC Test: 0.781\n",
      "AUC-PR Test: 0.360\n",
      "F1-score Test: 0.412\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.87      0.90       397\n",
      "         1.0       0.46      0.58      0.51        72\n",
      "\n",
      "    accuracy                           0.83       469\n",
      "   macro avg       0.69      0.73      0.70       469\n",
      "weighted avg       0.85      0.83      0.84       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.88      0.90       104\n",
      "         1.0       0.37      0.47      0.41        15\n",
      "\n",
      "    accuracy                           0.83       119\n",
      "   macro avg       0.64      0.68      0.66       119\n",
      "weighted avg       0.85      0.83      0.84       119\n",
      "\n",
      "\n",
      "\n",
      "========== RIASSUNTO FINALE ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Choose the ensemble models \n",
    "models = [XGBClassifier for _ in range(5)]\n",
    "\n",
    "# Seed\n",
    "rf_params = {\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "# Param grid space for Hyperparameter Tuning (it can be changed)\n",
    "params = {\n",
    "    \"n_estimators\": randint(10, 301),              \n",
    "    \"max_depth\": randint(3, 11),                     \n",
    "    \"learning_rate\": [1,0.1,0.01,0.3],             \n",
    "    \"subsample\": [0.4,0.5,0.6,0.8,1],                \n",
    "    \"colsample_bytree\": [0.7,0.9,1],   \n",
    "    \"min_child_weight\": randint(1, 11),          \n",
    "    \"gamma\": [0,0.1,0.01,0.3,0.5]                         \n",
    "}\n",
    "\n",
    "# Directory to save the results\n",
    "dir = 'Results/Models_Sensitivity/XGB'\n",
    "\n",
    "#Run the function\n",
    "train_model(df_clean, rf_params,models, params, shap_dir = dir, l=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcolo SHAP per KIN001-260 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   3%|▎         | 1/30 [00:25<12:26, 25.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for KIN001-260** \n",
      "AUC-ROC Test: 0.722\n",
      "AUC-PR Test: 0.553\n",
      "F1-score Test: 0.512\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.93      0.90       351\n",
      "         1.0       0.75      0.58      0.65       119\n",
      "\n",
      "    accuracy                           0.84       470\n",
      "   macro avg       0.81      0.76      0.78       470\n",
      "weighted avg       0.84      0.84      0.84       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89        93\n",
      "         1.0       0.65      0.42      0.51        26\n",
      "\n",
      "    accuracy                           0.82       119\n",
      "   macro avg       0.75      0.68      0.70       119\n",
      "weighted avg       0.81      0.82      0.81       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TG101348 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   7%|▋         | 2/30 [00:51<11:59, 25.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TG101348** \n",
      "AUC-ROC Test: 0.903\n",
      "AUC-PR Test: 0.749\n",
      "F1-score Test: 0.692\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.95       414\n",
      "         1.0       0.62      0.47      0.54        55\n",
      "\n",
      "    accuracy                           0.90       469\n",
      "   macro avg       0.78      0.72      0.74       469\n",
      "weighted avg       0.90      0.90      0.90       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96       107\n",
      "         1.0       0.64      0.75      0.69        12\n",
      "\n",
      "    accuracy                           0.93       119\n",
      "   macro avg       0.81      0.85      0.83       119\n",
      "weighted avg       0.94      0.93      0.94       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per BX-912 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  10%|█         | 3/30 [01:27<13:43, 30.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for BX-912** \n",
      "AUC-ROC Test: 0.941\n",
      "AUC-PR Test: 0.773\n",
      "F1-score Test: 0.690\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.90      0.91       410\n",
      "         1.0       0.40      0.48      0.44        60\n",
      "\n",
      "    accuracy                           0.84       470\n",
      "   macro avg       0.66      0.69      0.67       470\n",
      "weighted avg       0.86      0.84      0.85       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96       102\n",
      "         1.0       0.77      0.62      0.69        16\n",
      "\n",
      "    accuracy                           0.92       118\n",
      "   macro avg       0.86      0.80      0.82       118\n",
      "weighted avg       0.92      0.92      0.92       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per QL-XI-92 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  13%|█▎        | 4/30 [01:56<12:54, 29.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for QL-XI-92** \n",
      "AUC-ROC Test: 0.764\n",
      "AUC-PR Test: 0.641\n",
      "F1-score Test: 0.562\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.85      0.80       303\n",
      "         1.0       0.64      0.50      0.56       166\n",
      "\n",
      "    accuracy                           0.72       469\n",
      "   macro avg       0.70      0.67      0.68       469\n",
      "weighted avg       0.72      0.72      0.72       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.88      0.84        83\n",
      "         1.0       0.64      0.50      0.56        36\n",
      "\n",
      "    accuracy                           0.76       119\n",
      "   macro avg       0.72      0.69      0.70       119\n",
      "weighted avg       0.75      0.76      0.76       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Tubastatin A su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  17%|█▋        | 5/30 [02:22<11:53, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Tubastatin A** \n",
      "AUC-ROC Test: 0.778\n",
      "AUC-PR Test: 0.669\n",
      "F1-score Test: 0.557\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.86      0.82       320\n",
      "         1.0       0.61      0.49      0.54       147\n",
      "\n",
      "    accuracy                           0.74       467\n",
      "   macro avg       0.70      0.67      0.68       467\n",
      "weighted avg       0.73      0.74      0.73       467\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.87      0.85        85\n",
      "         1.0       0.61      0.52      0.56        33\n",
      "\n",
      "    accuracy                           0.77       118\n",
      "   macro avg       0.71      0.69      0.70       118\n",
      "weighted avg       0.76      0.77      0.77       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK690693 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  20%|██        | 6/30 [02:49<11:11, 28.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK690693** \n",
      "AUC-ROC Test: 0.712\n",
      "AUC-PR Test: 0.677\n",
      "F1-score Test: 0.556\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.81      0.78       308\n",
      "         1.0       0.57      0.48      0.53       161\n",
      "\n",
      "    accuracy                           0.70       469\n",
      "   macro avg       0.66      0.65      0.65       469\n",
      "weighted avg       0.69      0.70      0.69       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.86      0.80        76\n",
      "         1.0       0.65      0.49      0.56        41\n",
      "\n",
      "    accuracy                           0.73       117\n",
      "   macro avg       0.70      0.67      0.68       117\n",
      "weighted avg       0.72      0.73      0.72       117\n",
      "\n",
      "\n",
      "Calcolo SHAP per XMD14-99 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  23%|██▎       | 7/30 [03:40<13:33, 35.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for XMD14-99** \n",
      "AUC-ROC Test: 0.861\n",
      "AUC-PR Test: 0.460\n",
      "F1-score Test: 0.485\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.94       784\n",
      "         1.0       0.71      0.58      0.64       154\n",
      "\n",
      "    accuracy                           0.89       938\n",
      "   macro avg       0.82      0.77      0.79       938\n",
      "weighted avg       0.89      0.89      0.89       938\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.92       208\n",
      "         1.0       0.44      0.53      0.48        30\n",
      "\n",
      "    accuracy                           0.86       238\n",
      "   macro avg       0.69      0.72      0.70       238\n",
      "weighted avg       0.87      0.86      0.86       238\n",
      "\n",
      "\n",
      "Calcolo SHAP per NPK76-II-72-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  27%|██▋       | 8/30 [04:12<12:35, 34.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for NPK76-II-72-1** \n",
      "AUC-ROC Test: 0.965\n",
      "AUC-PR Test: 0.729\n",
      "F1-score Test: 0.556\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95       430\n",
      "         1.0       0.48      0.55      0.51        40\n",
      "\n",
      "    accuracy                           0.91       470\n",
      "   macro avg       0.72      0.75      0.73       470\n",
      "weighted avg       0.92      0.91      0.91       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       110\n",
      "         1.0       0.56      0.56      0.56         9\n",
      "\n",
      "    accuracy                           0.93       119\n",
      "   macro avg       0.76      0.76      0.76       119\n",
      "weighted avg       0.93      0.93      0.93       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Y-39983 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  30%|███       | 9/30 [05:04<13:55, 39.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Y-39983** \n",
      "AUC-ROC Test: 0.781\n",
      "AUC-PR Test: 0.757\n",
      "F1-score Test: 0.605\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.84      0.78       590\n",
      "         1.0       0.64      0.49      0.56       352\n",
      "\n",
      "    accuracy                           0.71       942\n",
      "   macro avg       0.69      0.66      0.67       942\n",
      "weighted avg       0.70      0.71      0.70       942\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.87      0.81       150\n",
      "         1.0       0.70      0.53      0.61        86\n",
      "\n",
      "    accuracy                           0.75       236\n",
      "   macro avg       0.73      0.70      0.71       236\n",
      "weighted avg       0.74      0.75      0.74       236\n",
      "\n",
      "\n",
      "Calcolo SHAP per AT-7519 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  33%|███▎      | 10/30 [05:37<12:36, 37.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for AT-7519** \n",
      "AUC-ROC Test: 0.969\n",
      "AUC-PR Test: 0.594\n",
      "F1-score Test: 0.400\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95       435\n",
      "         1.0       0.38      0.55      0.45        31\n",
      "\n",
      "    accuracy                           0.91       466\n",
      "   macro avg       0.67      0.74      0.70       466\n",
      "weighted avg       0.93      0.91      0.92       466\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99       114\n",
      "         1.0       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.97       118\n",
      "   macro avg       0.99      0.62      0.69       118\n",
      "weighted avg       0.98      0.97      0.97       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per KIN001-236 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  37%|███▋      | 11/30 [06:05<11:02, 34.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for KIN001-236** \n",
      "AUC-ROC Test: 0.827\n",
      "AUC-PR Test: 0.649\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95       414\n",
      "         1.0       0.60      0.57      0.59        56\n",
      "\n",
      "    accuracy                           0.90       470\n",
      "   macro avg       0.77      0.76      0.77       470\n",
      "weighted avg       0.90      0.90      0.90       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95       105\n",
      "         1.0       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.79      0.83      0.81       119\n",
      "weighted avg       0.92      0.92      0.92       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TL-2-105 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  40%|████      | 12/30 [06:37<10:11, 33.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TL-2-105** \n",
      "AUC-ROC Test: 0.883\n",
      "AUC-PR Test: 0.745\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95       415\n",
      "         1.0       0.73      0.44      0.55        54\n",
      "\n",
      "    accuracy                           0.92       469\n",
      "   macro avg       0.83      0.71      0.75       469\n",
      "weighted avg       0.91      0.92      0.91       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.93        99\n",
      "         1.0       0.68      0.65      0.67        20\n",
      "\n",
      "    accuracy                           0.89       119\n",
      "   macro avg       0.81      0.79      0.80       119\n",
      "weighted avg       0.89      0.89      0.89       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per ABT-263 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  43%|████▎     | 13/30 [07:47<12:40, 44.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for ABT-263** \n",
      "AUC-ROC Test: 0.833\n",
      "AUC-PR Test: 0.656\n",
      "F1-score Test: 0.545\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.90      0.89       966\n",
      "         1.0       0.65      0.56      0.60       303\n",
      "\n",
      "    accuracy                           0.82      1269\n",
      "   macro avg       0.76      0.73      0.74      1269\n",
      "weighted avg       0.82      0.82      0.82      1269\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.95      0.88       234\n",
      "         1.0       0.75      0.43      0.55        84\n",
      "\n",
      "    accuracy                           0.81       318\n",
      "   macro avg       0.79      0.69      0.71       318\n",
      "weighted avg       0.80      0.81      0.79       318\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK1070916 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  47%|████▋     | 14/30 [08:14<10:31, 39.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK1070916** \n",
      "AUC-ROC Test: 0.937\n",
      "AUC-PR Test: 0.715\n",
      "F1-score Test: 0.519\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.93      0.91       380\n",
      "         1.0       0.57      0.44      0.49        78\n",
      "\n",
      "    accuracy                           0.85       458\n",
      "   macro avg       0.73      0.68      0.70       458\n",
      "weighted avg       0.83      0.85      0.84       458\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.94       100\n",
      "         1.0       0.64      0.44      0.52        16\n",
      "\n",
      "    accuracy                           0.89       116\n",
      "   macro avg       0.78      0.70      0.73       116\n",
      "weighted avg       0.88      0.89      0.88       116\n",
      "\n",
      "\n",
      "Calcolo SHAP per Methotrexate su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  50%|█████     | 15/30 [08:48<09:26, 37.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Methotrexate** \n",
      "AUC-ROC Test: 0.822\n",
      "AUC-PR Test: 0.410\n",
      "F1-score Test: 0.232\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87       355\n",
      "         1.0       0.40      0.55      0.46        69\n",
      "\n",
      "    accuracy                           0.79       424\n",
      "   macro avg       0.65      0.69      0.67       424\n",
      "weighted avg       0.82      0.79      0.80       424\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.46      0.63        97\n",
      "         1.0       0.13      0.89      0.23         9\n",
      "\n",
      "    accuracy                           0.50       106\n",
      "   macro avg       0.56      0.68      0.43       106\n",
      "weighted avg       0.91      0.50      0.60       106\n",
      "\n",
      "\n",
      "Calcolo SHAP per TL-1-85 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  53%|█████▎    | 16/30 [09:36<09:34, 41.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TL-1-85** \n",
      "AUC-ROC Test: 0.954\n",
      "AUC-PR Test: 0.717\n",
      "F1-score Test: 0.571\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97       435\n",
      "         1.0       0.58      0.54      0.56        35\n",
      "\n",
      "    accuracy                           0.94       470\n",
      "   macro avg       0.77      0.76      0.76       470\n",
      "weighted avg       0.93      0.94      0.94       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       104\n",
      "         1.0       0.62      0.53      0.57        15\n",
      "\n",
      "    accuracy                           0.90       119\n",
      "   macro avg       0.77      0.74      0.76       119\n",
      "weighted avg       0.89      0.90      0.90       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per T0901317 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  57%|█████▋    | 17/30 [10:38<10:12, 47.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for T0901317** \n",
      "AUC-ROC Test: 0.883\n",
      "AUC-PR Test: 0.608\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95       814\n",
      "         1.0       0.65      0.61      0.63       118\n",
      "\n",
      "    accuracy                           0.91       932\n",
      "   macro avg       0.80      0.78      0.79       932\n",
      "weighted avg       0.91      0.91      0.91       932\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96       206\n",
      "         1.0       0.75      0.60      0.67        30\n",
      "\n",
      "    accuracy                           0.92       236\n",
      "   macro avg       0.85      0.79      0.81       236\n",
      "weighted avg       0.92      0.92      0.92       236\n",
      "\n",
      "\n",
      "Calcolo SHAP per PHA-793887 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  60%|██████    | 18/30 [11:06<08:19, 41.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for PHA-793887** \n",
      "AUC-ROC Test: 0.969\n",
      "AUC-PR Test: 0.595\n",
      "F1-score Test: 0.600\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.92      0.91       414\n",
      "         1.0       0.35      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.85       469\n",
      "   macro avg       0.63      0.62      0.63       469\n",
      "weighted avg       0.84      0.85      0.85       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96       113\n",
      "         1.0       0.43      1.00      0.60         6\n",
      "\n",
      "    accuracy                           0.93       119\n",
      "   macro avg       0.71      0.96      0.78       119\n",
      "weighted avg       0.97      0.93      0.94       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per JW-7-24-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  63%|██████▎   | 19/30 [11:36<06:56, 37.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for JW-7-24-1** \n",
      "AUC-ROC Test: 0.911\n",
      "AUC-PR Test: 0.562\n",
      "F1-score Test: 0.564\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       417\n",
      "         1.0       0.68      0.62      0.65        52\n",
      "\n",
      "    accuracy                           0.93       469\n",
      "   macro avg       0.82      0.79      0.80       469\n",
      "weighted avg       0.92      0.93      0.92       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.91       103\n",
      "         1.0       0.48      0.69      0.56        16\n",
      "\n",
      "    accuracy                           0.86       119\n",
      "   macro avg       0.71      0.79      0.74       119\n",
      "weighted avg       0.88      0.86      0.87       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TPCA-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  67%|██████▋   | 20/30 [12:11<06:11, 37.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TPCA-1** \n",
      "AUC-ROC Test: 0.947\n",
      "AUC-PR Test: 0.599\n",
      "F1-score Test: 0.381\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.90      0.93       425\n",
      "         1.0       0.39      0.58      0.46        45\n",
      "\n",
      "    accuracy                           0.87       470\n",
      "   macro avg       0.67      0.74      0.70       470\n",
      "weighted avg       0.90      0.87      0.88       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       108\n",
      "         1.0       0.40      0.36      0.38        11\n",
      "\n",
      "    accuracy                           0.89       119\n",
      "   macro avg       0.67      0.65      0.66       119\n",
      "weighted avg       0.89      0.89      0.89       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per CX-5461 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Processing Drugs:  70%|███████   | 21/30 [12:47<05:30, 36.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for CX-5461** \n",
      "AUC-ROC Test: 0.676\n",
      "AUC-PR Test: 0.747\n",
      "F1-score Test: 0.721\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.65      0.61       208\n",
      "         1.0       0.69      0.60      0.64       260\n",
      "\n",
      "    accuracy                           0.63       468\n",
      "   macro avg       0.63      0.63      0.63       468\n",
      "weighted avg       0.63      0.63      0.63       468\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.56      1.00      0.72        66\n",
      "\n",
      "    accuracy                           0.56       117\n",
      "   macro avg       0.28      0.50      0.36       117\n",
      "weighted avg       0.32      0.56      0.41       117\n",
      "\n",
      "\n",
      "Calcolo SHAP per STF-62247 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  73%|███████▎  | 22/30 [13:59<06:19, 47.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for STF-62247** \n",
      "AUC-ROC Test: 0.710\n",
      "AUC-PR Test: 0.530\n",
      "F1-score Test: 0.541\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.91      0.91       394\n",
      "         1.0       0.49      0.48      0.49        73\n",
      "\n",
      "    accuracy                           0.84       467\n",
      "   macro avg       0.70      0.69      0.70       467\n",
      "weighted avg       0.84      0.84      0.84       467\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.94      0.91        97\n",
      "         1.0       0.62      0.48      0.54        21\n",
      "\n",
      "    accuracy                           0.86       118\n",
      "   macro avg       0.76      0.71      0.73       118\n",
      "weighted avg       0.84      0.86      0.85       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per Dabrafenib su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  77%|███████▋  | 23/30 [14:27<04:49, 41.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Dabrafenib** \n",
      "AUC-ROC Test: 0.665\n",
      "AUC-PR Test: 0.243\n",
      "F1-score Test: 0.276\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.92      0.90       366\n",
      "         1.0       0.55      0.45      0.49        78\n",
      "\n",
      "    accuracy                           0.84       444\n",
      "   macro avg       0.72      0.68      0.70       444\n",
      "weighted avg       0.83      0.84      0.83       444\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.90      0.89        96\n",
      "         1.0       0.29      0.27      0.28        15\n",
      "\n",
      "    accuracy                           0.81       111\n",
      "   macro avg       0.59      0.58      0.58       111\n",
      "weighted avg       0.81      0.81      0.81       111\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK429286A su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  80%|████████  | 24/30 [15:01<03:55, 39.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK429286A** \n",
      "AUC-ROC Test: 0.864\n",
      "AUC-PR Test: 0.624\n",
      "F1-score Test: 0.629\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.97      0.94       416\n",
      "         1.0       0.53      0.30      0.39        53\n",
      "\n",
      "    accuracy                           0.89       469\n",
      "   macro avg       0.72      0.63      0.66       469\n",
      "weighted avg       0.87      0.89      0.88       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.94       100\n",
      "         1.0       0.69      0.58      0.63        19\n",
      "\n",
      "    accuracy                           0.89       119\n",
      "   macro avg       0.80      0.76      0.78       119\n",
      "weighted avg       0.88      0.89      0.89       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Trametinib su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  83%|████████▎ | 25/30 [15:35<03:09, 37.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Trametinib** \n",
      "AUC-ROC Test: 0.805\n",
      "AUC-PR Test: 0.720\n",
      "F1-score Test: 0.611\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.81      0.79       305\n",
      "         1.0       0.55      0.49      0.52       146\n",
      "\n",
      "    accuracy                           0.71       451\n",
      "   macro avg       0.66      0.65      0.65       451\n",
      "weighted avg       0.70      0.71      0.70       451\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.52      0.65        75\n",
      "         1.0       0.48      0.85      0.61        39\n",
      "\n",
      "    accuracy                           0.63       114\n",
      "   macro avg       0.67      0.68      0.63       114\n",
      "weighted avg       0.73      0.63      0.64       114\n",
      "\n",
      "\n",
      "Calcolo SHAP per NG-25 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  87%|████████▋ | 26/30 [16:07<02:23, 35.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for NG-25** \n",
      "AUC-ROC Test: 0.953\n",
      "AUC-PR Test: 0.733\n",
      "F1-score Test: 0.545\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95       428\n",
      "         1.0       0.54      0.50      0.52        42\n",
      "\n",
      "    accuracy                           0.92       470\n",
      "   macro avg       0.74      0.73      0.74       470\n",
      "weighted avg       0.91      0.92      0.92       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95       105\n",
      "         1.0       0.75      0.43      0.55        14\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.84      0.70      0.75       119\n",
      "weighted avg       0.91      0.92      0.91       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per BIX02189 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  90%|█████████ | 27/30 [16:44<01:49, 36.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for BIX02189** \n",
      "AUC-ROC Test: 0.933\n",
      "AUC-PR Test: 0.673\n",
      "F1-score Test: 0.710\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95       429\n",
      "         1.0       0.42      0.41      0.42        41\n",
      "\n",
      "    accuracy                           0.90       470\n",
      "   macro avg       0.68      0.68      0.68       470\n",
      "weighted avg       0.90      0.90      0.90       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       103\n",
      "         1.0       0.73      0.69      0.71        16\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.84      0.82      0.83       119\n",
      "weighted avg       0.92      0.92      0.92       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per PIK-93 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  93%|█████████▎| 28/30 [17:49<01:29, 44.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for PIK-93** \n",
      "AUC-ROC Test: 0.816\n",
      "AUC-PR Test: 0.679\n",
      "F1-score Test: 0.640\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       804\n",
      "         1.0       0.65      0.57      0.61       136\n",
      "\n",
      "    accuracy                           0.89       940\n",
      "   macro avg       0.79      0.76      0.77       940\n",
      "weighted avg       0.89      0.89      0.89       940\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       212\n",
      "         1.0       0.67      0.62      0.64        26\n",
      "\n",
      "    accuracy                           0.92       238\n",
      "   macro avg       0.81      0.79      0.80       238\n",
      "weighted avg       0.92      0.92      0.92       238\n",
      "\n",
      "\n",
      "Calcolo SHAP per XMD15-27 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  97%|█████████▋| 29/30 [20:46<01:24, 84.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for XMD15-27** \n",
      "AUC-ROC Test: 0.965\n",
      "AUC-PR Test: 0.821\n",
      "F1-score Test: 0.778\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94      2045\n",
      "         1.0       0.61      0.62      0.61       300\n",
      "\n",
      "    accuracy                           0.90      2345\n",
      "   macro avg       0.78      0.78      0.78      2345\n",
      "weighted avg       0.90      0.90      0.90      2345\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.94      0.96       515\n",
      "         1.0       0.70      0.88      0.78        80\n",
      "\n",
      "    accuracy                           0.93       595\n",
      "   macro avg       0.84      0.91      0.87       595\n",
      "weighted avg       0.94      0.93      0.94       595\n",
      "\n",
      "\n",
      "Calcolo SHAP per AC220 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs: 100%|██████████| 30/30 [21:21<00:00, 42.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for AC220** \n",
      "AUC-ROC Test: 0.799\n",
      "AUC-PR Test: 0.455\n",
      "F1-score Test: 0.452\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.92      0.91       397\n",
      "         1.0       0.52      0.44      0.48        72\n",
      "\n",
      "    accuracy                           0.85       469\n",
      "   macro avg       0.71      0.68      0.70       469\n",
      "weighted avg       0.84      0.85      0.85       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.91      0.92       104\n",
      "         1.0       0.44      0.47      0.45        15\n",
      "\n",
      "    accuracy                           0.86       119\n",
      "   macro avg       0.68      0.69      0.68       119\n",
      "weighted avg       0.86      0.86      0.86       119\n",
      "\n",
      "\n",
      "\n",
      "========== RIASSUNTO FINALE ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = [GradientBoostingClassifier for _ in range(5)]\n",
    "\n",
    "#Seed\n",
    "rf_params = {\n",
    "        \"random_state\": 1,\n",
    "    }\n",
    "\n",
    "# Hyp Tuning\n",
    "params = {\n",
    "    \"n_estimators\": randint(10, 301),            \n",
    "    \"max_depth\": randint(3, 11),                   \n",
    "    \"learning_rate\": [1, 0.1, 0.01, 0.3],          \n",
    "    \"subsample\": [0.4, 0.5, 0.6, 0.8, 1],          \n",
    "    \"min_samples_split\": randint(2, 11),          \n",
    "    \"min_samples_leaf\": randint(1, 11),            \n",
    "    \"max_features\": ['sqrt', 'log2', None]         \n",
    "}\n",
    "\n",
    "# Directory to save the results\n",
    "dir = 'Results/Models_Sensitivity/Gradient_Boosting'\n",
    "\n",
    "#Run the function\n",
    "train_model(df_clean, rf_params, models, params, shap_dir = dir, l=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB_XGB_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcolo SHAP per KIN001-260 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   3%|▎         | 1/30 [00:40<19:29, 40.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for KIN001-260** \n",
      "AUC-ROC Test: 0.748\n",
      "AUC-PR Test: 0.598\n",
      "F1-score Test: 0.565\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91       351\n",
      "         1.0       0.78      0.61      0.69       119\n",
      "\n",
      "    accuracy                           0.86       470\n",
      "   macro avg       0.83      0.78      0.80       470\n",
      "weighted avg       0.85      0.86      0.85       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.92      0.90        93\n",
      "         1.0       0.65      0.50      0.57        26\n",
      "\n",
      "    accuracy                           0.83       119\n",
      "   macro avg       0.76      0.71      0.73       119\n",
      "weighted avg       0.82      0.83      0.82       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TG101348 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:   7%|▋         | 2/30 [01:27<20:49, 44.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TG101348** \n",
      "AUC-ROC Test: 0.904\n",
      "AUC-PR Test: 0.617\n",
      "F1-score Test: 0.643\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94       414\n",
      "         1.0       0.58      0.56      0.57        55\n",
      "\n",
      "    accuracy                           0.90       469\n",
      "   macro avg       0.76      0.76      0.76       469\n",
      "weighted avg       0.90      0.90      0.90       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95       107\n",
      "         1.0       0.56      0.75      0.64        12\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.77      0.84      0.80       119\n",
      "weighted avg       0.93      0.92      0.92       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per BX-912 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  10%|█         | 3/30 [02:03<18:07, 40.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for BX-912** \n",
      "AUC-ROC Test: 0.948\n",
      "AUC-PR Test: 0.757\n",
      "F1-score Test: 0.583\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.91      0.92       410\n",
      "         1.0       0.45      0.48      0.46        60\n",
      "\n",
      "    accuracy                           0.86       470\n",
      "   macro avg       0.68      0.70      0.69       470\n",
      "weighted avg       0.86      0.86      0.86       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95       102\n",
      "         1.0       0.88      0.44      0.58        16\n",
      "\n",
      "    accuracy                           0.92       118\n",
      "   macro avg       0.90      0.71      0.77       118\n",
      "weighted avg       0.91      0.92      0.90       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per QL-XI-92 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  13%|█▎        | 4/30 [02:34<15:59, 36.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for QL-XI-92** \n",
      "AUC-ROC Test: 0.749\n",
      "AUC-PR Test: 0.647\n",
      "F1-score Test: 0.543\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.86      0.81       303\n",
      "         1.0       0.66      0.51      0.57       166\n",
      "\n",
      "    accuracy                           0.73       469\n",
      "   macro avg       0.71      0.68      0.69       469\n",
      "weighted avg       0.73      0.73      0.72       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.72      0.76        83\n",
      "         1.0       0.49      0.61      0.54        36\n",
      "\n",
      "    accuracy                           0.69       119\n",
      "   macro avg       0.65      0.67      0.65       119\n",
      "weighted avg       0.71      0.69      0.70       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Tubastatin A su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  17%|█▋        | 5/30 [03:06<14:37, 35.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Tubastatin A** \n",
      "AUC-ROC Test: 0.779\n",
      "AUC-PR Test: 0.658\n",
      "F1-score Test: 0.490\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.83      0.81       320\n",
      "         1.0       0.59      0.54      0.56       147\n",
      "\n",
      "    accuracy                           0.74       467\n",
      "   macro avg       0.70      0.68      0.69       467\n",
      "weighted avg       0.73      0.74      0.74       467\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.95      0.87        85\n",
      "         1.0       0.75      0.36      0.49        33\n",
      "\n",
      "    accuracy                           0.79       118\n",
      "   macro avg       0.77      0.66      0.68       118\n",
      "weighted avg       0.78      0.79      0.76       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK690693 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  20%|██        | 6/30 [03:43<14:20, 35.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK690693** \n",
      "AUC-ROC Test: 0.704\n",
      "AUC-PR Test: 0.640\n",
      "F1-score Test: 0.548\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.81      0.78       308\n",
      "         1.0       0.57      0.48      0.52       161\n",
      "\n",
      "    accuracy                           0.70       469\n",
      "   macro avg       0.66      0.65      0.65       469\n",
      "weighted avg       0.69      0.70      0.69       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.84      0.80        76\n",
      "         1.0       0.62      0.49      0.55        41\n",
      "\n",
      "    accuracy                           0.72       117\n",
      "   macro avg       0.69      0.66      0.67       117\n",
      "weighted avg       0.71      0.72      0.71       117\n",
      "\n",
      "\n",
      "Calcolo SHAP per XMD14-99 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  23%|██▎       | 7/30 [04:47<17:15, 45.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for XMD14-99** \n",
      "AUC-ROC Test: 0.875\n",
      "AUC-PR Test: 0.473\n",
      "F1-score Test: 0.500\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.96      0.94       784\n",
      "         1.0       0.73      0.58      0.65       154\n",
      "\n",
      "    accuracy                           0.90       938\n",
      "   macro avg       0.82      0.77      0.79       938\n",
      "weighted avg       0.89      0.90      0.89       938\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.88      0.91       208\n",
      "         1.0       0.43      0.60      0.50        30\n",
      "\n",
      "    accuracy                           0.85       238\n",
      "   macro avg       0.68      0.74      0.71       238\n",
      "weighted avg       0.87      0.85      0.86       238\n",
      "\n",
      "\n",
      "Calcolo SHAP per NPK76-II-72-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  27%|██▋       | 8/30 [05:20<15:00, 40.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for NPK76-II-72-1** \n",
      "AUC-ROC Test: 0.965\n",
      "AUC-PR Test: 0.733\n",
      "F1-score Test: 0.700\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95       430\n",
      "         1.0       0.50      0.55      0.52        40\n",
      "\n",
      "    accuracy                           0.91       470\n",
      "   macro avg       0.73      0.75      0.74       470\n",
      "weighted avg       0.92      0.91      0.92       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97       110\n",
      "         1.0       0.64      0.78      0.70         9\n",
      "\n",
      "    accuracy                           0.95       119\n",
      "   macro avg       0.81      0.87      0.84       119\n",
      "weighted avg       0.96      0.95      0.95       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Y-39983 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  30%|███       | 9/30 [06:21<16:34, 47.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Y-39983** \n",
      "AUC-ROC Test: 0.773\n",
      "AUC-PR Test: 0.735\n",
      "F1-score Test: 0.620\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.81      0.78       590\n",
      "         1.0       0.63      0.53      0.58       352\n",
      "\n",
      "    accuracy                           0.71       942\n",
      "   macro avg       0.69      0.67      0.68       942\n",
      "weighted avg       0.70      0.71      0.70       942\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.65      0.72       150\n",
      "         1.0       0.54      0.72      0.62        86\n",
      "\n",
      "    accuracy                           0.68       236\n",
      "   macro avg       0.67      0.69      0.67       236\n",
      "weighted avg       0.71      0.68      0.68       236\n",
      "\n",
      "\n",
      "Calcolo SHAP per AT-7519 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  33%|███▎      | 10/30 [06:54<14:21, 43.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for AT-7519** \n",
      "AUC-ROC Test: 0.978\n",
      "AUC-PR Test: 0.500\n",
      "F1-score Test: 0.500\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97       435\n",
      "         1.0       0.56      0.71      0.63        31\n",
      "\n",
      "    accuracy                           0.94       466\n",
      "   macro avg       0.77      0.84      0.80       466\n",
      "weighted avg       0.95      0.94      0.95       466\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98       114\n",
      "         1.0       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.97       118\n",
      "   macro avg       0.74      0.74      0.74       118\n",
      "weighted avg       0.97      0.97      0.97       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per KIN001-236 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  37%|███▋      | 11/30 [07:34<13:20, 42.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for KIN001-236** \n",
      "AUC-ROC Test: 0.830\n",
      "AUC-PR Test: 0.617\n",
      "F1-score Test: 0.588\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94       414\n",
      "         1.0       0.55      0.57      0.56        56\n",
      "\n",
      "    accuracy                           0.89       470\n",
      "   macro avg       0.75      0.75      0.75       470\n",
      "weighted avg       0.90      0.89      0.89       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93       105\n",
      "         1.0       0.50      0.71      0.59        14\n",
      "\n",
      "    accuracy                           0.88       119\n",
      "   macro avg       0.73      0.81      0.76       119\n",
      "weighted avg       0.91      0.88      0.89       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TL-2-105 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  40%|████      | 12/30 [08:11<12:07, 40.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TL-2-105** \n",
      "AUC-ROC Test: 0.874\n",
      "AUC-PR Test: 0.720\n",
      "F1-score Test: 0.629\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95       415\n",
      "         1.0       0.61      0.50      0.55        54\n",
      "\n",
      "    accuracy                           0.91       469\n",
      "   macro avg       0.78      0.73      0.75       469\n",
      "weighted avg       0.90      0.91      0.90       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.96      0.94        99\n",
      "         1.0       0.73      0.55      0.63        20\n",
      "\n",
      "    accuracy                           0.89       119\n",
      "   macro avg       0.82      0.75      0.78       119\n",
      "weighted avg       0.88      0.89      0.88       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per ABT-263 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  43%|████▎     | 13/30 [09:34<15:08, 53.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for ABT-263** \n",
      "AUC-ROC Test: 0.810\n",
      "AUC-PR Test: 0.690\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.92      0.90       966\n",
      "         1.0       0.69      0.59      0.64       303\n",
      "\n",
      "    accuracy                           0.84      1269\n",
      "   macro avg       0.78      0.76      0.77      1269\n",
      "weighted avg       0.83      0.84      0.83      1269\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.92      0.89       234\n",
      "         1.0       0.74      0.61      0.67        84\n",
      "\n",
      "    accuracy                           0.84       318\n",
      "   macro avg       0.80      0.77      0.78       318\n",
      "weighted avg       0.83      0.84      0.83       318\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK1070916 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  47%|████▋     | 14/30 [10:06<12:29, 46.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK1070916** \n",
      "AUC-ROC Test: 0.955\n",
      "AUC-PR Test: 0.767\n",
      "F1-score Test: 0.714\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.91      0.91       380\n",
      "         1.0       0.55      0.53      0.54        78\n",
      "\n",
      "    accuracy                           0.85       458\n",
      "   macro avg       0.73      0.72      0.72       458\n",
      "weighted avg       0.84      0.85      0.85       458\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96       100\n",
      "         1.0       0.83      0.62      0.71        16\n",
      "\n",
      "    accuracy                           0.93       116\n",
      "   macro avg       0.89      0.80      0.84       116\n",
      "weighted avg       0.93      0.93      0.93       116\n",
      "\n",
      "\n",
      "Calcolo SHAP per Methotrexate su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  50%|█████     | 15/30 [10:43<10:55, 43.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Methotrexate** \n",
      "AUC-ROC Test: 0.812\n",
      "AUC-PR Test: 0.308\n",
      "F1-score Test: 0.583\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.92      0.92       355\n",
      "         1.0       0.60      0.64      0.62        69\n",
      "\n",
      "    accuracy                           0.87       424\n",
      "   macro avg       0.77      0.78      0.77       424\n",
      "weighted avg       0.88      0.87      0.87       424\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.92      0.95        97\n",
      "         1.0       0.47      0.78      0.58         9\n",
      "\n",
      "    accuracy                           0.91       106\n",
      "   macro avg       0.72      0.85      0.77       106\n",
      "weighted avg       0.93      0.91      0.92       106\n",
      "\n",
      "\n",
      "Calcolo SHAP per TL-1-85 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  53%|█████▎    | 16/30 [11:14<09:19, 39.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TL-1-85** \n",
      "AUC-ROC Test: 0.921\n",
      "AUC-PR Test: 0.493\n",
      "F1-score Test: 0.625\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96       435\n",
      "         1.0       0.51      0.60      0.55        35\n",
      "\n",
      "    accuracy                           0.93       470\n",
      "   macro avg       0.74      0.78      0.76       470\n",
      "weighted avg       0.93      0.93      0.93       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94       104\n",
      "         1.0       0.59      0.67      0.62        15\n",
      "\n",
      "    accuracy                           0.90       119\n",
      "   macro avg       0.77      0.80      0.78       119\n",
      "weighted avg       0.91      0.90      0.90       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per T0901317 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  57%|█████▋    | 17/30 [12:13<09:55, 45.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for T0901317** \n",
      "AUC-ROC Test: 0.883\n",
      "AUC-PR Test: 0.711\n",
      "F1-score Test: 0.645\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.94       814\n",
      "         1.0       0.61      0.67      0.64       118\n",
      "\n",
      "    accuracy                           0.90       932\n",
      "   macro avg       0.78      0.80      0.79       932\n",
      "weighted avg       0.91      0.90      0.91       932\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95       206\n",
      "         1.0       0.62      0.67      0.65        30\n",
      "\n",
      "    accuracy                           0.91       236\n",
      "   macro avg       0.79      0.80      0.80       236\n",
      "weighted avg       0.91      0.91      0.91       236\n",
      "\n",
      "\n",
      "Calcolo SHAP per PHA-793887 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  60%|██████    | 18/30 [13:07<09:38, 48.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for PHA-793887** \n",
      "AUC-ROC Test: 0.969\n",
      "AUC-PR Test: 0.526\n",
      "F1-score Test: 0.632\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93       414\n",
      "         1.0       0.46      0.47      0.46        55\n",
      "\n",
      "    accuracy                           0.87       469\n",
      "   macro avg       0.69      0.70      0.70       469\n",
      "weighted avg       0.87      0.87      0.87       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97       113\n",
      "         1.0       0.46      1.00      0.63         6\n",
      "\n",
      "    accuracy                           0.94       119\n",
      "   macro avg       0.73      0.97      0.80       119\n",
      "weighted avg       0.97      0.94      0.95       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per JW-7-24-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  63%|██████▎   | 19/30 [13:48<08:26, 46.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for JW-7-24-1** \n",
      "AUC-ROC Test: 0.902\n",
      "AUC-PR Test: 0.553\n",
      "F1-score Test: 0.634\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       417\n",
      "         1.0       0.60      0.60      0.60        52\n",
      "\n",
      "    accuracy                           0.91       469\n",
      "   macro avg       0.77      0.77      0.77       469\n",
      "weighted avg       0.91      0.91      0.91       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.88      0.92       103\n",
      "         1.0       0.52      0.81      0.63        16\n",
      "\n",
      "    accuracy                           0.87       119\n",
      "   macro avg       0.74      0.85      0.78       119\n",
      "weighted avg       0.91      0.87      0.88       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per TPCA-1 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  67%|██████▋   | 20/30 [14:20<06:59, 41.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for TPCA-1** \n",
      "AUC-ROC Test: 0.952\n",
      "AUC-PR Test: 0.651\n",
      "F1-score Test: 0.500\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       425\n",
      "         1.0       0.52      0.51      0.52        45\n",
      "\n",
      "    accuracy                           0.91       470\n",
      "   macro avg       0.74      0.73      0.73       470\n",
      "weighted avg       0.91      0.91      0.91       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.94       108\n",
      "         1.0       0.46      0.55      0.50        11\n",
      "\n",
      "    accuracy                           0.90       119\n",
      "   macro avg       0.71      0.74      0.72       119\n",
      "weighted avg       0.91      0.90      0.90       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per CX-5461 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Processing Drugs:  70%|███████   | 21/30 [14:51<05:47, 38.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for CX-5461** \n",
      "AUC-ROC Test: 0.668\n",
      "AUC-PR Test: 0.752\n",
      "F1-score Test: 0.721\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.69      0.63       208\n",
      "         1.0       0.71      0.60      0.65       260\n",
      "\n",
      "    accuracy                           0.64       468\n",
      "   macro avg       0.64      0.65      0.64       468\n",
      "weighted avg       0.65      0.64      0.64       468\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        51\n",
      "         1.0       0.56      1.00      0.72        66\n",
      "\n",
      "    accuracy                           0.56       117\n",
      "   macro avg       0.28      0.50      0.36       117\n",
      "weighted avg       0.32      0.56      0.41       117\n",
      "\n",
      "\n",
      "Calcolo SHAP per STF-62247 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  73%|███████▎  | 22/30 [15:21<04:48, 36.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for STF-62247** \n",
      "AUC-ROC Test: 0.773\n",
      "AUC-PR Test: 0.588\n",
      "F1-score Test: 0.541\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.93       394\n",
      "         1.0       0.62      0.52      0.57        73\n",
      "\n",
      "    accuracy                           0.88       467\n",
      "   macro avg       0.77      0.73      0.75       467\n",
      "weighted avg       0.87      0.88      0.87       467\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.94      0.91        97\n",
      "         1.0       0.62      0.48      0.54        21\n",
      "\n",
      "    accuracy                           0.86       118\n",
      "   macro avg       0.76      0.71      0.73       118\n",
      "weighted avg       0.84      0.86      0.85       118\n",
      "\n",
      "\n",
      "Calcolo SHAP per Dabrafenib su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  77%|███████▋  | 23/30 [16:05<04:28, 38.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Dabrafenib** \n",
      "AUC-ROC Test: 0.692\n",
      "AUC-PR Test: 0.258\n",
      "F1-score Test: 0.240\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.91      0.91       366\n",
      "         1.0       0.56      0.55      0.55        78\n",
      "\n",
      "    accuracy                           0.84       444\n",
      "   macro avg       0.73      0.73      0.73       444\n",
      "weighted avg       0.84      0.84      0.84       444\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.93      0.90        96\n",
      "         1.0       0.30      0.20      0.24        15\n",
      "\n",
      "    accuracy                           0.83       111\n",
      "   macro avg       0.59      0.56      0.57       111\n",
      "weighted avg       0.80      0.83      0.81       111\n",
      "\n",
      "\n",
      "Calcolo SHAP per GSK429286A su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  80%|████████  | 24/30 [16:36<03:36, 36.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for GSK429286A** \n",
      "AUC-ROC Test: 0.884\n",
      "AUC-PR Test: 0.703\n",
      "F1-score Test: 0.649\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93       416\n",
      "         1.0       0.42      0.42      0.42        53\n",
      "\n",
      "    accuracy                           0.87       469\n",
      "   macro avg       0.67      0.67      0.67       469\n",
      "weighted avg       0.87      0.87      0.87       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94       100\n",
      "         1.0       0.67      0.63      0.65        19\n",
      "\n",
      "    accuracy                           0.89       119\n",
      "   macro avg       0.80      0.79      0.79       119\n",
      "weighted avg       0.89      0.89      0.89       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per Trametinib su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  83%|████████▎ | 25/30 [17:05<02:49, 33.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for Trametinib** \n",
      "AUC-ROC Test: 0.799\n",
      "AUC-PR Test: 0.702\n",
      "F1-score Test: 0.608\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.81      0.81       305\n",
      "         1.0       0.61      0.61      0.61       146\n",
      "\n",
      "    accuracy                           0.75       451\n",
      "   macro avg       0.71      0.71      0.71       451\n",
      "weighted avg       0.75      0.75      0.75       451\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.79      0.79        75\n",
      "         1.0       0.60      0.62      0.61        39\n",
      "\n",
      "    accuracy                           0.73       114\n",
      "   macro avg       0.70      0.70      0.70       114\n",
      "weighted avg       0.73      0.73      0.73       114\n",
      "\n",
      "\n",
      "Calcolo SHAP per NG-25 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  87%|████████▋ | 26/30 [17:35<02:11, 32.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for NG-25** \n",
      "AUC-ROC Test: 0.929\n",
      "AUC-PR Test: 0.694\n",
      "F1-score Test: 0.545\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95       428\n",
      "         1.0       0.54      0.45      0.49        42\n",
      "\n",
      "    accuracy                           0.92       470\n",
      "   macro avg       0.74      0.71      0.72       470\n",
      "weighted avg       0.91      0.92      0.91       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.98      0.95       105\n",
      "         1.0       0.75      0.43      0.55        14\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.84      0.70      0.75       119\n",
      "weighted avg       0.91      0.92      0.91       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per BIX02189 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  90%|█████████ | 27/30 [18:05<01:36, 32.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for BIX02189** \n",
      "AUC-ROC Test: 0.930\n",
      "AUC-PR Test: 0.633\n",
      "F1-score Test: 0.710\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.94       429\n",
      "         1.0       0.41      0.44      0.42        41\n",
      "\n",
      "    accuracy                           0.90       470\n",
      "   macro avg       0.68      0.69      0.68       470\n",
      "weighted avg       0.90      0.90      0.90       470\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       103\n",
      "         1.0       0.73      0.69      0.71        16\n",
      "\n",
      "    accuracy                           0.92       119\n",
      "   macro avg       0.84      0.82      0.83       119\n",
      "weighted avg       0.92      0.92      0.92       119\n",
      "\n",
      "\n",
      "Calcolo SHAP per PIK-93 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  93%|█████████▎| 28/30 [19:06<01:21, 40.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for PIK-93** \n",
      "AUC-ROC Test: 0.862\n",
      "AUC-PR Test: 0.769\n",
      "F1-score Test: 0.667\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       804\n",
      "         1.0       0.66      0.56      0.60       136\n",
      "\n",
      "    accuracy                           0.89       940\n",
      "   macro avg       0.79      0.75      0.77       940\n",
      "weighted avg       0.89      0.89      0.89       940\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.96       212\n",
      "         1.0       0.64      0.69      0.67        26\n",
      "\n",
      "    accuracy                           0.92       238\n",
      "   macro avg       0.80      0.82      0.81       238\n",
      "weighted avg       0.93      0.92      0.93       238\n",
      "\n",
      "\n",
      "Calcolo SHAP per XMD15-27 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs:  97%|█████████▋| 29/30 [21:31<01:12, 72.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for XMD15-27** \n",
      "AUC-ROC Test: 0.944\n",
      "AUC-PR Test: 0.813\n",
      "F1-score Test: 0.688\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93      2045\n",
      "         1.0       0.56      0.58      0.57       300\n",
      "\n",
      "    accuracy                           0.89      2345\n",
      "   macro avg       0.75      0.76      0.75      2345\n",
      "weighted avg       0.89      0.89      0.89      2345\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       515\n",
      "         1.0       0.69      0.69      0.69        80\n",
      "\n",
      "    accuracy                           0.92       595\n",
      "   macro avg       0.82      0.82      0.82       595\n",
      "weighted avg       0.92      0.92      0.92       595\n",
      "\n",
      "\n",
      "Calcolo SHAP per AC220 su 5 modelli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Drugs: 100%|██████████| 30/30 [22:01<00:00, 44.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Results for AC220** \n",
      "AUC-ROC Test: 0.809\n",
      "AUC-PR Test: 0.453\n",
      "F1-score Test: 0.400\n",
      "\n",
      " **Validation Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.91      0.92       397\n",
      "         1.0       0.53      0.56      0.54        72\n",
      "\n",
      "    accuracy                           0.86       469\n",
      "   macro avg       0.73      0.73      0.73       469\n",
      "weighted avg       0.86      0.86      0.86       469\n",
      "\n",
      "\n",
      "**Test Set Classification Report:**\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.88      0.90       104\n",
      "         1.0       0.35      0.47      0.40        15\n",
      "\n",
      "    accuracy                           0.82       119\n",
      "   macro avg       0.63      0.67      0.65       119\n",
      "weighted avg       0.85      0.82      0.83       119\n",
      "\n",
      "\n",
      "\n",
      "========== RIASSUNTO FINALE ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = [XGBClassifier, GradientBoostingClassifier, RandomForestClassifier, RandomForestClassifier,XGBClassifier ]\n",
    "\n",
    "#Seed\n",
    "rf_params = {\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "#Hyp Tuning\n",
    "param_grid = {\n",
    "    \"n_estimators\": randint(10, 501),              \n",
    "    \"max_depth\": [5, 7, 10, 20, None]\n",
    "}\n",
    "\n",
    "#Directory\n",
    "dir = 'Results/Models_Sensitivity/XGB_RF_GB'\n",
    "\n",
    "#Run\n",
    "train_model(df_clean, rf_params, models, param_grid, dir, l=31)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
